{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:03:22.305734Z",
     "start_time": "2019-07-27T08:03:16.498947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tf_contrib\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "\n",
    "import random\n",
    "\n",
    "import pylab\n",
    "import tfplot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tfx\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from cleverhans.loss import SNNLCrossEntropy\n",
    "\n",
    "# tensorflow specific settings\n",
    "tf.enable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "# which GPU to be used (0 is RTX, 1 or 2 are either of the Titan Xps)\n",
    "gpu = \"/GPU:0\"\n",
    "\n",
    "AUTOTUNE = tf.contrib.data.AUTOTUNE\n",
    "\n",
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.allow_growth = True\n",
    "session_config.allow_soft_placement = True\n",
    "\n",
    "# session_config.log_device_placement = True\n",
    "tf.keras.backend.set_session(tf.Session(config=session_config))\n",
    "\n",
    "# make sure tensorflow-gpu is being used\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:03:22.437753Z",
     "start_time": "2019-07-27T08:03:22.307765Z"
    },
    "code_folding": [
     14,
     49,
     77,
     80,
     84,
     87,
     103
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Xavier : tf_contrib.layers.xavier_initializer()\n",
    "# He : tf_contrib.layers.variance_scaling_initializer()\n",
    "# Normal : tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
    "# l2_decay : tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "weight_init = tf_contrib.layers.variance_scaling_initializer()\n",
    "weight_regularizer = tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Layer\n",
    "##################################################################################\n",
    "\n",
    "def conv(x, channels, kernel=4, stride=2, padding='SAME', use_bias=True, scope='conv_0'):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = tf.layers.conv2d(inputs=x, filters=channels,\n",
    "                             kernel_size=kernel, kernel_initializer=weight_init,\n",
    "                             kernel_regularizer=weight_regularizer,\n",
    "                             strides=stride, use_bias=use_bias, padding=padding)\n",
    "\n",
    "        return x\n",
    "\n",
    "def fully_connected(x, units, use_bias=True, scope='fully_0'):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = flatten(x)\n",
    "        x = tf.layers.dense(x, units=units, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resblock(x_init, channels, kernel=3, is_training=True, use_bias=True, downsample=False, scope='resblock') :\n",
    "    with tf.variable_scope(scope) :\n",
    "\n",
    "        x = batch_norm(x_init, is_training, scope='batch_norm_0')\n",
    "        x = relu(x)\n",
    "\n",
    "        if downsample :\n",
    "            x = conv(x, channels, kernel=kernel, stride=2, use_bias=use_bias, scope='conv_0')\n",
    "            x_init = conv(x_init, channels, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        else :\n",
    "            x = conv(x, channels, kernel=kernel, stride=1, use_bias=use_bias, scope='conv_0')\n",
    "\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_1')\n",
    "        x = relu(x)\n",
    "        x = conv(x, channels, kernel=kernel, stride=1, use_bias=use_bias, scope='conv_1')\n",
    "\n",
    "        return x + x_init\n",
    "\n",
    "def bottle_resblock(x_init, channels, is_training=True, use_bias=True, downsample=False, scope='bottle_resblock') :\n",
    "    with tf.variable_scope(scope) :\n",
    "        x = batch_norm(x_init, is_training, scope='batch_norm_1x1_front')\n",
    "        shortcut = relu(x)\n",
    "\n",
    "        x = conv(shortcut, channels, kernel=1, stride=1, use_bias=use_bias, scope='conv_1x1_front')\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_3x3')\n",
    "        x = relu(x)\n",
    "\n",
    "        if downsample :\n",
    "            x = conv(x, channels, kernel=3, stride=2, use_bias=use_bias, scope='conv_0')\n",
    "            shortcut = conv(shortcut, channels*4, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        else :\n",
    "            x = conv(x, channels, kernel=3, stride=1, use_bias=use_bias, scope='conv_0')\n",
    "            shortcut = conv(shortcut, channels * 4, kernel=1, stride=1, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_1x1_back')\n",
    "        x = relu(x)\n",
    "        x = conv(x, channels*4, kernel=1, stride=1, use_bias=use_bias, scope='conv_1x1_back')\n",
    "\n",
    "        return x + shortcut\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Sampling\n",
    "##################################################################################\n",
    "\n",
    "def flatten(x) :\n",
    "    return tf.layers.flatten(x)\n",
    "\n",
    "def global_avg_pooling(x):\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "    return gap\n",
    "\n",
    "def avg_pooling(x) :\n",
    "    return tf.layers.average_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "def max_pooling(x) :\n",
    "    return tf.layers.max_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "##################################################################################\n",
    "# Activation function\n",
    "##################################################################################\n",
    "\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Normalization function\n",
    "##################################################################################\n",
    "\n",
    "def batch_norm(x, is_training=True, scope='batch_norm'):\n",
    "    return tf_contrib.layers.batch_norm(x,\n",
    "                                        decay=0.9, epsilon=1e-05,\n",
    "                                        center=True, scale=True, updates_collections=None,\n",
    "                                        is_training=is_training, scope=scope)\n",
    "\n",
    "##################################################################################\n",
    "# Loss function\n",
    "##################################################################################\n",
    "\n",
    "def classification_loss(logit, label) :\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logit))\n",
    "    prediction = tf.equal(tf.argmax(logit, -1), tf.argmax(label, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:03:22.453547Z",
     "start_time": "2019-07-27T08:03:22.439460Z"
    },
    "code_folding": [
     1,
     6,
     13,
     19
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def rotate(image):\n",
    "    \n",
    "    return tf.image.rot90(image, tf.random_uniform(shape=[], minval=0, maxval=4, \n",
    "                                               dtype=tf.int32))\n",
    "\n",
    "def flip(image):\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def crop(image, range_start=0.8, range_end=1.0):\n",
    "    \n",
    "    image = tf.image.central_crop(image, central_fraction=random.uniform(range_start, range_end))\n",
    "    image = tf.image.resize_images(image,tf.constant([512, 512]))\n",
    "    return image\n",
    "\n",
    "def translate(image,  x_max=75, y_max=75):\n",
    "    \n",
    "    return tf.contrib.image.translate(image, translations=[random.uniform(-1 * x_max, x_max), \n",
    "                                                           random.uniform(-1 * y_max, y_max)])\n",
    "\n",
    "def augment_image(image):\n",
    "                       \n",
    "    image = rotate(image)\n",
    "    image = flip(image)\n",
    "    \n",
    "    image = translate(image)\n",
    "    image = crop(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data (PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a directory of data of the form: ~/data/labels/images.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:03:22.537831Z",
     "start_time": "2019-07-27T08:03:22.455270Z"
    },
    "code_folding": [
     42,
     51
    ]
   },
   "outputs": [],
   "source": [
    "# load an array of image paths\n",
    "def load_image_paths(path):\n",
    "    \n",
    "    data_root = pathlib.Path(path)\n",
    "    \n",
    "    # create a list of every file and its label index\n",
    "    all_image_paths = list(data_root.glob('*/*'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]\n",
    "    \n",
    "    return all_image_paths\n",
    "\n",
    "# randomly shuffle train and test values and split based on parameters\n",
    "def split(image_paths, split=[0.6,0.2,0.2], seed=777):\n",
    "    random.Random(seed).shuffle(image_paths)\n",
    "    \n",
    "    boundary1 = int(len(image_paths) * split[0])\n",
    "    boundary2 = int(len(image_paths) * (split[0]+split[1]))\n",
    "    \n",
    "    train = image_paths[:boundary1]\n",
    "    evaluate = image_paths[boundary1: boundary2]\n",
    "    test = image_paths[boundary2:]\n",
    "    \n",
    "    return train, evaluate, test\n",
    "\n",
    "# preprocessing functions\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, shape=[512,512])\n",
    "    image = tf.div(\n",
    "       tf.subtract(\n",
    "          image, \n",
    "          tf.reduce_min(image)\n",
    "       ), \n",
    "       tf.subtract(\n",
    "          tf.reduce_max(image), \n",
    "          tf.reduce_min(image)\n",
    "       )\n",
    "    )\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path, training=True):\n",
    "    image = tf.read_file(path)\n",
    "    image = preprocess_image(image)\n",
    "    \n",
    "    if (training):\n",
    "        image = augment_image(image[:,:,None])\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load(path, image_paths, training=True, batch_size=64, shuffle=True, drop_remainder=False):\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        # data root\n",
    "        data_root = pathlib.Path(path)\n",
    "\n",
    "        # return label names\n",
    "        label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "\n",
    "        # assign index to label\n",
    "        label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "        # array of all labels corresponding to image_paths\n",
    "        all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                            for path in image_paths]\n",
    "\n",
    "        # make path dataset\n",
    "        path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "\n",
    "        # get image tensors by mapping function over the path dataset\n",
    "        image_ds = path_ds.map(lambda path : load_and_preprocess_image(path, training=training))\n",
    "\n",
    "        # create label dataset\n",
    "        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
    "\n",
    "        # zip together image and label dataset into dataset of tuples for\n",
    "        # estimator input\n",
    "        image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "        # Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "        # completely shuffled\n",
    "        \n",
    "        image_label_ds = image_label_ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "        \n",
    "        if (training):\n",
    "            print(\"shuffling and repeating b/c training flag set\")\n",
    "\n",
    "            image_label_ds = image_label_ds.repeat()\n",
    "        else:\n",
    "            image_label_ds = image_label_ds.repeat(count=1)\n",
    "        \n",
    "        \n",
    "        if (shuffle):\n",
    "            image_label_ds = image_label_ds.shuffle(buffer_size = len(image_paths))\n",
    "            \n",
    "        # `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "        image_label_ds = image_label_ds.prefetch(6)\n",
    "       \n",
    "        \n",
    "        return image_label_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:13:28.385392Z",
     "start_time": "2019-06-25T17:11:53.702Z"
    }
   },
   "source": [
    "# ResNet-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:03:22.554443Z",
     "start_time": "2019-07-27T08:03:22.539398Z"
    },
    "code_folding": [
     14,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# adapted from https://github.com/grishasergei/conviz/\n",
    "def prime_powers(n):\n",
    "    \"\"\"\n",
    "    Compute the factors of a positive integer\n",
    "    Algorithm from https://rosettacode.org/wiki/Factors_of_an_integer#Python\n",
    "    :param n: int\n",
    "    :return: set\n",
    "    \"\"\"\n",
    "    factors = set()\n",
    "    for x in range(1, int(np.sqrt(n)) + 1):\n",
    "        if n % x == 0:\n",
    "            factors.add(int(x))\n",
    "            factors.add(int(n // x))\n",
    "    return sorted(factors)\n",
    "\n",
    "def get_grid_dim(x):\n",
    "    \"\"\"\n",
    "    Transforms x into product of two integers\n",
    "    :param x: int\n",
    "    :return: two ints\n",
    "    \"\"\"\n",
    "    factors = prime_powers(x)\n",
    "    if len(factors) % 2 == 0:\n",
    "        i = int(len(factors) / 2)\n",
    "        return factors[i], factors[i - 1]\n",
    "\n",
    "    i = len(factors) // 2\n",
    "    return factors[i], factors[i]\n",
    "\n",
    "def pca(X, num_observations=64, n_dimensions = 50):\n",
    "    singular_values, u, _ = tf.svd(X)\n",
    "    sigma = tf.diag(singular_values)\n",
    "    print(sigma)\n",
    "    \n",
    "    sigma = tf.slice(sigma, [0, 0], [num_observations, n_dimensions])\n",
    "    \n",
    "    pca = tf.matmul(u, sigma)\n",
    "    pca = tf.transpose(pca)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Convolution Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:04:33.219465Z",
     "start_time": "2019-07-27T08:04:33.197123Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "@tfplot.wrap\n",
    "def plot_conv_weights(weights, channels_all=True):\n",
    "    \"\"\"\n",
    "    Plots convolutional filters\n",
    "    :param weights: numpy array of rank 4\n",
    "    :param channels_all: boolean, optional\n",
    "\n",
    "    \"\"\"\n",
    "    w_min = np.min(weights)\n",
    "    w_max = np.max(weights)\n",
    "\n",
    "    channels = [0]\n",
    "    # make a list of channels if all are plotted\n",
    "    if channels_all:\n",
    "        channels = range(weights.shape[2])\n",
    "\n",
    "    # get number of convolutional filters\n",
    "    num_filters = weights.shape[3]\n",
    "\n",
    "    # get number of grid rows and columns\n",
    "    grid_r, grid_c = get_grid_dim(num_filters)\n",
    "    \n",
    "   \n",
    "\n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(min([grid_r, grid_c]), max([grid_r, grid_c]))\n",
    "\n",
    "    # iterate channels\n",
    "    for channel in channels:\n",
    "        # iterate filters inside every channel\n",
    "        for l, ax in enumerate(axes.flat):\n",
    "            # get a single filter\n",
    "            img = weights[:, :, channel, l]\n",
    "            # put it on the grid\n",
    "            ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n",
    "            \n",
    "            # remove any labels from the axes\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:09:34.807955Z",
     "start_time": "2019-07-27T08:09:34.768767Z"
    }
   },
   "outputs": [],
   "source": [
    "@tfplot.wrap\n",
    "def plot_conv_output(conv_img, name):\n",
    "    \"\"\"\n",
    "    Makes plots of results of performing convolution\n",
    "    :param conv_img: numpy array of rank 4\n",
    "    :param name: string, name of convolutional layer\n",
    "    :return: nothing, plots are saved on the disk\n",
    "    \"\"\"\n",
    "    w_min = np.min(conv_img)\n",
    "    w_max = np.max(conv_img)\n",
    "\n",
    "    # get number of convolutional filters\n",
    "    num_filters = conv_img.shape[3]\n",
    "\n",
    "    # get number of grid rows and columns\n",
    "    grid_r, grid_c = get_grid_dim(num_filters)\n",
    "    \n",
    "\n",
    "    if (min([grid_r, grid_c]) == 1 and max([grid_r, grid_c]) == 1):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(24,24))   \n",
    "        fig.suptitle(name, fontsize=25, color='k')\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        \n",
    "        img = conv_img[0, :, :,  0]\n",
    "        ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='bicubic', cmap='Greys_r')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        plt.subplots_adjust(top=0.85)\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "        \n",
    "        \n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(min([grid_r, grid_c]),\n",
    "                             max([grid_r, grid_c]),\n",
    "                            figsize=(24,15))\n",
    "    fig.suptitle(name, fontsize=25, color='k')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    # iterate filters\n",
    "    for l, ax in enumerate(axes.flat):\n",
    "        # get a single image\n",
    "        img = conv_img[0, :, :,  l]\n",
    "        # put it on the grid\n",
    "        ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='bicubic', cmap='jet')\n",
    "        # remove any labels from the axes\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "       \n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T08:09:36.211311Z",
     "start_time": "2019-07-27T08:09:36.001073Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "# ResNet-10 architecture\n",
    "def resnet10_network(x, conv_kernel=7, resblock_kernel=3, num_channels=4, n_classes=num_classes, reuse = False, is_training = True):\n",
    "    with tf.variable_scope('Resnet-10', reuse = reuse), tf.device(gpu):\n",
    "        \n",
    "        x = tf.reshape(x, shape=[-1, 512, 512, 1])\n",
    "        # channels\n",
    "        \n",
    "        filtered_images = []\n",
    "        \n",
    "        filtered_images.append(tf.identity(x))\n",
    "        \n",
    "        x = conv(x, num_channels, kernel=conv_kernel, stride=1, padding='SAME')\n",
    "        \n",
    "        filtered_images.append(tf.identity(x))\n",
    "        \n",
    "        x = resblock(x, channels=num_channels, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock1_id1')      \n",
    "   \n",
    "        filtered_images.append(tf.identity(x))\n",
    "\n",
    "        x = resblock(x, channels=num_channels * 2, kernel=resblock_kernel, is_training=is_training, \n",
    "                     downsample=True, scope='resblock2_conv1')\n",
    "        \n",
    "        filtered_images.append(tf.identity(x))\n",
    "\n",
    "        x = resblock(x, channels=num_channels * 2, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock3_id2')\n",
    "        \n",
    "        filtered_images.append(tf.identity(x))\n",
    "        \n",
    "        x = resblock(x, channels=num_channels * 4, kernel=resblock_kernel, is_training=is_training, \n",
    "                     downsample=True, scope='resblock4_conv2')\n",
    "\n",
    "        filtered_images.append(tf.identity(x))\n",
    "        \n",
    "        x = resblock(x, channels=num_channels * 4, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock5_id3')\n",
    "        \n",
    "        filtered_images.append(tf.identity(x))\n",
    "        \n",
    "        \n",
    "        x = batch_norm(x, is_training, scope='batch_norm')\n",
    "        \n",
    "        x = relu(x)\n",
    "        \n",
    "        x_pre_flatten = tf.identity(x)\n",
    "        \n",
    "        x = fully_connected(x, num_classes)\n",
    "        \n",
    "        return x, x_pre_flatten, filtered_images\n",
    "\n",
    "    \n",
    "def resnet10_model_fn(features, labels, mode, conv_kernel=7, resblock_kernel=3, num_channels=4, snnl_weight=0.05,\n",
    "                      log=True):\n",
    "    with tf.device(gpu):\n",
    "\n",
    "        print(\"in gpu part\")\n",
    "        logits_train, activ_maps_train, filtered_images = resnet10_network(features,\n",
    "                                                          conv_kernel=conv_kernel,\n",
    "                                                          resblock_kernel=resblock_kernel,\n",
    "                                                          num_channels=num_channels,\n",
    "                                                          n_classes=num_classes,\n",
    "                                                          reuse=False,\n",
    "                                                          is_training=True)\n",
    "\n",
    "        logits_test, activ_maps_test, _ = resnet10_network(features,\n",
    "                                                        conv_kernel=conv_kernel,\n",
    "                                                        resblock_kernel=resblock_kernel,\n",
    "                                                        num_channels=num_channels,\n",
    "                                                        n_classes=num_classes,\n",
    "                                                        reuse=True,\n",
    "                                                        is_training=False)\n",
    "\n",
    "        pred_classes = tf.arg_max(logits_test, dimension=1)\n",
    "\n",
    "        # PREDICT MODE\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=pred_classes)\n",
    "\n",
    "\n",
    "        loss_op = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "\n",
    "        loss_op = (1.0 - snnl_weight) * loss_op + snnl_weight * SNNLCrossEntropy.optimized_temp_SNNL(\n",
    "            flatten(activ_maps_train), labels, 20.0, True)\n",
    "        \n",
    "        acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        tf.summary.scalar(\"loss\", loss_op)\n",
    "        tf.summary.scalar(\"accuracy\", acc_op[1])\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "            # the different ops for training, evaluating, ...\n",
    "            estim_specs = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=pred_classes,\n",
    "                loss=loss_op,\n",
    "                train_op=train_op,\n",
    "                eval_metric_ops={'accuracy': acc_op}\n",
    "            )\n",
    "\n",
    "            return estim_specs\n",
    "    \n",
    "#     for var in tf.trainable_variables():\n",
    "#         print(var.name)\n",
    "    \n",
    "        conv0_weights = [v for v in tf.global_variables() if v.name == \"Resnet-10/conv_0/conv2d/kernel:0\"][0]\n",
    "        \n",
    "        plot_op_expanded = tf.expand_dims(plot_conv_weights(conv0_weights), 0)\n",
    "        tf.summary.image(\"conv_0_weight_plots\", plot_op_expanded)\n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"activation_maps\"):\n",
    "            \n",
    "            level_dict = {0: \"0_original_image\",         \n",
    "                          1 : \"1_after_initial_conv\",\n",
    "                          2 : \"2_after_resblock1_id1\",\n",
    "                          3 : \"3_after_resblock2_conv1\",\n",
    "                          4 : \"4_after_resblock3_id2\",\n",
    "                          5 : \"5_after_resblock4_conv2\",\n",
    "                          6 : \"6_after_resblock5_id3\"}\n",
    "            \n",
    "            counter = 0\n",
    "            \n",
    "            plot_ops = []\n",
    "\n",
    "            for filtered_im in filtered_images:\n",
    "               \n",
    "                activation_map = tf.slice(filtered_im,[0, 0, 0, 0],[1, -1, -1, -1])\n",
    "                activation_op = tf.expand_dims(plot_conv_output(activation_map, level_dict[counter]), 0)\n",
    "\n",
    "                plot_ops.append(activation_op)\n",
    "\n",
    "                counter = counter + 1\n",
    "                \n",
    "            final_log_op = tf.concat(plot_ops, 1)\n",
    "        \n",
    "            tf.summary.image(\"image_display\", final_log_op)\n",
    "        \n",
    "        \n",
    "#         level_dict = {0: \"0_original_image\",\n",
    "            \n",
    "#                       1 : \"1_after_initial_conv\",\n",
    "#                       2 : \"2_after_resblock1_id1\",\n",
    "#                       3 : \"3_after_resblock2_conv1\",\n",
    "#                       4 : \"4_after_resblock3_id2\",\n",
    "#                       5 : \"5_after_resblock4_conv2\",\n",
    "#                       6 : \"6_after_resblock5_id3\"}\n",
    "        \n",
    "#         with tf.name_scope(\"activation_maps\"):\n",
    "            \n",
    "#             counter = 0\n",
    "            \n",
    "\n",
    "#             for filtered_im in filtered_images:\n",
    "            \n",
    "#                 with tf.name_scope(level_dict[counter]): \n",
    "#                     activation_map = tf.slice(filtered_im,[0, 0, 0, 0],[1, -1, -1, -1])\n",
    "#                     activation_op = tf.expand_dims(plot_conv_output(activation_map), 0)\n",
    "                    \n",
    "#                     print(activation_op)\n",
    "                    \n",
    "#                     tf.summary.image(\"filtered_images\", activation_op)\n",
    "\n",
    "#                 counter = counter + 1\n",
    "            \n",
    "        eval_summary_hook = tf.train.SummarySaverHook(\n",
    "            save_steps=1,\n",
    "            output_dir=model_path + \"/eval_images\",\n",
    "            summary_op=tf.summary.merge_all())\n",
    "        # Add it to the evaluation_hook list\n",
    "        evaluation_hooks = []\n",
    "        evaluation_hooks.append(eval_summary_hook)\n",
    "\n",
    "        # the different ops for training, evaluating, ...\n",
    "        estim_specs = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss_op,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={'accuracy': acc_op},\n",
    "            evaluation_hooks=evaluation_hooks\n",
    "        )\n",
    "\n",
    "        return estim_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-27T08:09:36.927Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jma/model/resnet10_test/kernel3_filter8_snnl0.05/\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/data/jma/model/resnet10_test/kernel3_filter8_snnl0.05/', '_tf_random_seed': 777, '_save_summary_steps': 20, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 20, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f945d12a5f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 120.\n",
      "shuffling and repeating b/c training flag set\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "in gpu part\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/jma/model/resnet10_test/kernel3_filter8_snnl0.05/model.ckpt-395\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 395 into /data/jma/model/resnet10_test/kernel3_filter8_snnl0.05/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4402863, step = 395\n",
      "INFO:tensorflow:global_step/sec: 2.4091\n",
      "INFO:tensorflow:loss = 1.0511872, step = 415 (8.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.39719\n",
      "INFO:tensorflow:loss = 0.78387755, step = 435 (8.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.4051\n",
      "INFO:tensorflow:loss = 0.8278537, step = 455 (8.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.51997\n",
      "INFO:tensorflow:loss = 0.94861823, step = 475 (7.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.38535\n",
      "INFO:tensorflow:loss = 0.6885835, step = 495 (8.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.42264\n",
      "INFO:tensorflow:loss = 0.7472062, step = 515 (8.252 sec)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "b_size = 32\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "random_seed = 777\n",
    "\n",
    "num_steps = 10000\n",
    "\n",
    "resnet10_checkpoint_path_base = \"/data/jma/model/resnet10_test/\"\n",
    "\n",
    "# kernel_sizes = [7, 9, 10, 11, 13]\n",
    "# filter_sizes = [10]\n",
    "# snnl_weights = [0.0]\n",
    "\n",
    "kernel_sizes = [3, 5, 7]\n",
    "filter_sizes = [8]\n",
    "snnl_weights = [0.05]\n",
    "\n",
    "data_root = \"./data_3classes/\"\n",
    "\n",
    "image_paths = load_image_paths(data_root)\n",
    "train_paths, eval_paths, test_paths = split(image_paths, seed=random_seed)\n",
    "\n",
    "train_input_fn = lambda : load(data_root, train_paths, training=True, batch_size=32, shuffle=False)\n",
    "eval_input_fn = lambda : load(data_root, eval_paths, training=False, batch_size=32, shuffle=False)\n",
    "test_input_fn = lambda : load(data_root, test_paths, training=False, shuffle=False)\n",
    "\n",
    "for filter_size in filter_sizes:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        \n",
    "        for snnl_weight in snnl_weights:\n",
    "            tf.summary.FileWriterCache.clear()\n",
    " \n",
    "            model_path = resnet10_checkpoint_path_base + \"kernel\" + str(kernel_size) + \"_filter\" + str(filter_size) + \"_snnl\" + str(snnl_weight)+\"/\"\n",
    "            print(model_path)\n",
    "\n",
    "            config = tf.estimator.RunConfig(\n",
    "                log_step_count_steps= 20,\n",
    "                save_summary_steps= 20,\n",
    "                save_checkpoints_secs= 120,\n",
    "                model_dir=model_path,\n",
    "                tf_random_seed=random_seed,\n",
    "                session_config=session_config)\n",
    "\n",
    "            model_fn = lambda features, labels, mode: resnet10_model_fn(features, labels, mode, \n",
    "                                                                        conv_kernel=kernel_size, \n",
    "                                                                        num_channels=filter_size,\n",
    "                                                                        snnl_weight=snnl_weight)\n",
    "\n",
    "            model = tf.estimator.Estimator(model_fn=model_fn, config=config)\n",
    "\n",
    "            train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=num_steps)\n",
    "            eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, throttle_secs=15)\n",
    "\n",
    "            tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metric Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def path_to_label(paths, data_root):\n",
    "\n",
    "    data_root = pathlib.Path(data_root)\n",
    "\n",
    "    # return label names\n",
    "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "\n",
    "    # assign index to label\n",
    "    label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "    # array of all labels corresponding to image_paths\n",
    "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                        for path in paths]\n",
    "    \n",
    "    return all_image_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "resnet10_checkpoint_path_base = \"/home_local/jma/model/resnet10/\"\n",
    "\n",
    "kernel_sizes = [10]\n",
    "filter_sizes = [16]\n",
    "\n",
    "data_path = \"./data_3classes/\"\n",
    "\n",
    "random_seed = 777\n",
    "\n",
    "image_paths = load_image_paths(data_path)\n",
    "train_paths, eval_paths, test_paths = split(image_paths, seed=random_seed)\n",
    "\n",
    "train_input_fn = lambda : load(data_path, train_paths, training=True)\n",
    "eval_input_fn = lambda : load(data_path, eval_paths, training=False)\n",
    "test_input_fn = lambda : load(data_path, test_paths, training=False)\n",
    "\n",
    "for filter_size in filter_sizes:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        \n",
    "        tf.summary.FileWriterCache.clear()\n",
    "        \n",
    "        model_path = resnet10_checkpoint_path_base + \"kernel\" + str(kernel_size) + \"_filter\" + str(filter_size) + \"/\"\n",
    "        print(model_path)\n",
    "        \n",
    "        \n",
    "        model_fn = lambda features, labels, mode: resnet10_model_fn(features, labels, mode, \n",
    "                                                                    conv_kernel=kernel_size, \n",
    "                                                                    num_channels=filter_size)\n",
    "        model = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_path)\n",
    "        \n",
    "        values = model.predict(eval_input_fn)\n",
    "        \n",
    "        \n",
    "        original_labels = path_to_label(eval_paths, data_path)\n",
    "        predicted_labels = list(values)\n",
    "        \n",
    "        cm = tf.confusion_matrix(original_labels, predicted_labels)\n",
    "        cm = tf.to_float(cm)\n",
    "    \n",
    "        cm = tf.div(cm, len(original_labels))\n",
    "\n",
    "        \n",
    "        cm = cm.numpy()\n",
    "        df_cm = pd.DataFrame(cm, range(3), range(3))\n",
    "        #plt.figure(figsize = (10,7))\n",
    "        sn.set(font_scale=1.4)#for label size\n",
    "        sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrectly Classified Images (PNG Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "resnet10_checkpoint_path_base = \"/home_local/jma/model/resnet10/\"\n",
    "\n",
    "kernel_sizes = [3,4,5,6,7,8,9,19]\n",
    "filter_sizes = [4, 10, 16]\n",
    "\n",
    "data_path = \"./data_3classes/\"\n",
    "\n",
    "image_paths = load_image_paths(data_path)\n",
    "train_paths, eval_paths, test_paths = split(image_paths, seed=random_seed)\n",
    "\n",
    "\n",
    "train_input_fn = lambda : load(data_path, train_paths, training=True)\n",
    "eval_input_fn = lambda : load(data_path, eval_paths, training=False)\n",
    "test_input_fn = lambda : load(data_path, test_paths, training=False)\n",
    "\n",
    "# change these======\n",
    "working_paths = eval_paths\n",
    "working_input_fn = eval_input_fn\n",
    "\n",
    "kernel_size=8\n",
    "filter_size=10\n",
    "#=========\n",
    "\n",
    "model_path = resnet10_checkpoint_path_base + \"kernel\" + str(kernel_size) + \"_filter\" + str(filter_size) + \"/\"\n",
    "print(model_path)\n",
    "\n",
    "model_fn = lambda features, labels, mode: resnet10_model_fn(features, labels, mode, \n",
    "                                                            conv_kernel=kernel_size, \n",
    "                                                            num_channels=filter_size)\n",
    "model = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_path)\n",
    "\n",
    "values = model.predict(working_input_fn)\n",
    "\n",
    "original_labels = path_to_label(working_paths, data_path)\n",
    "predicted_labels = list(values)\n",
    "\n",
    "# make a plot?\n",
    "\n",
    "for index in range(len(working_paths)):\n",
    "    if original_labels[index] != predicted_labels[index]:\n",
    "        # add image to plot\n",
    "\n",
    "        img = Image.open(working_paths[index])\n",
    "        \n",
    "        basewidth = 256\n",
    "\n",
    "        wpercent = (basewidth/float(img.size[0]))\n",
    "        hsize = int((float(img.size[1])*float(wpercent)))\n",
    "        img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "\n",
    "        \n",
    "        d = ImageDraw.Draw(img)\n",
    "        \n",
    "        # debug this shit\n",
    "        d.text((10,10), \"True: \" + str(original_labels[index]) + \n",
    "               \", Pred: \" + str(predicted_labels[index]), \n",
    "               fill=\"white\", font=ImageFont.truetype(\"./fonts/arial-bold.ttf\", 15))       \n",
    "                \n",
    "        display(img)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
