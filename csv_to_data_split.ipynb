{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ratings from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:34:32.005402Z",
     "start_time": "2019-08-13T16:34:31.993477Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_ratings_list(log_path):\n",
    "    \n",
    "    ratings_list = []\n",
    "    \n",
    "    with open(log_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        row_count = 0\n",
    "\n",
    "        for row in csv_reader:\n",
    "\n",
    "            # ignore column name row\n",
    "            if (row_count != 0):\n",
    "\n",
    "                ratings_list.append([row[1], int(row[2])])\n",
    "\n",
    "            row_count = row_count + 1\n",
    "        \n",
    "    return ratings_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-Rater Variability Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:34:34.137657Z",
     "start_time": "2019-08-13T16:34:34.116450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['IM-0001-0001-0001.dcm', 1], ['IM-0001-0002-0001.dcm', 0], ['IM-0001-0003-0001.dcm', 2], ['IM-0001-0004-0001.dcm', 1], ['IM-0001-0005-0001.dcm', 1], ['IM-0001-0006-0001.dcm', 1], ['IM-0001-0007-0001.dcm', 1], ['IM-0001-0008-0001.dcm', 1], ['IM-0001-0009-0001.dcm', 0], ['IM-0001-0010-0001.dcm', 1]]\n",
      "[['IM-0001-0001-0001.dcm', 2], ['IM-0001-0002-0001.dcm', 0], ['IM-0001-0003-0001.dcm', 1], ['IM-0001-0004-0001.dcm', 1], ['IM-0001-0005-0001.dcm', 1], ['IM-0001-0006-0001.dcm', 1], ['IM-0001-0007-0001.dcm', 1], ['IM-0001-0008-0001.dcm', 1], ['IM-0001-0009-0001.dcm', 1], ['IM-0001-0010-0001.dcm', 1]]\n"
     ]
    }
   ],
   "source": [
    "def get_first(elem):\n",
    "    return elem[0]\n",
    "\n",
    "\n",
    "log_path_ali = \"./data/logs/ratings_ali.csv\"\n",
    "log_path_peter = \"./data/logs/ratings_peter.csv\"\n",
    "\n",
    "ratings_ali = get_ratings_list(log_path_ali)\n",
    "ratings_peter = get_ratings_list(log_path_peter)\n",
    "\n",
    "ratings_ali = sorted(ratings_ali, key=get_first)\n",
    "ratings_peter = sorted(ratings_peter, key=get_first)\n",
    "\n",
    "print(ratings_ali[:10])\n",
    "print(ratings_peter[:10])\n",
    "\n",
    "\n",
    "#check if length of two 2d arrays are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Folder Structure from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T17:45:38.744801Z",
     "start_time": "2019-08-13T17:45:13.228833Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using rater log: ratings_ali.csv\n",
      "outputting to: ./data/generated_sets/ali_labels/\n",
      "progress: 0/2111\n",
      "progress: 10/2111\n",
      "progress: 20/2111\n",
      "progress: 30/2111\n",
      "progress: 40/2111\n",
      "progress: 50/2111\n",
      "progress: 60/2111\n",
      "progress: 70/2111\n",
      "progress: 80/2111\n",
      "progress: 90/2111\n",
      "progress: 100/2111\n",
      "progress: 110/2111\n",
      "progress: 120/2111\n",
      "progress: 130/2111\n",
      "progress: 140/2111\n",
      "progress: 150/2111\n",
      "progress: 160/2111\n",
      "progress: 170/2111\n",
      "progress: 180/2111\n",
      "progress: 190/2111\n",
      "progress: 200/2111\n",
      "progress: 210/2111\n",
      "progress: 220/2111\n",
      "progress: 230/2111\n",
      "progress: 240/2111\n",
      "progress: 250/2111\n",
      "progress: 260/2111\n",
      "progress: 270/2111\n",
      "progress: 280/2111\n",
      "progress: 290/2111\n",
      "progress: 300/2111\n",
      "progress: 310/2111\n",
      "progress: 320/2111\n",
      "progress: 330/2111\n",
      "progress: 340/2111\n",
      "progress: 350/2111\n",
      "progress: 360/2111\n",
      "progress: 370/2111\n",
      "progress: 380/2111\n",
      "progress: 390/2111\n",
      "progress: 400/2111\n",
      "progress: 410/2111\n",
      "progress: 420/2111\n",
      "progress: 430/2111\n",
      "progress: 440/2111\n",
      "progress: 450/2111\n",
      "progress: 460/2111\n",
      "progress: 470/2111\n",
      "progress: 480/2111\n",
      "progress: 490/2111\n",
      "progress: 500/2111\n",
      "progress: 510/2111\n",
      "progress: 520/2111\n",
      "progress: 530/2111\n",
      "progress: 540/2111\n",
      "progress: 550/2111\n",
      "progress: 560/2111\n",
      "progress: 570/2111\n",
      "progress: 580/2111\n",
      "progress: 590/2111\n",
      "progress: 600/2111\n",
      "progress: 610/2111\n",
      "progress: 620/2111\n",
      "progress: 630/2111\n",
      "progress: 640/2111\n",
      "progress: 650/2111\n",
      "progress: 660/2111\n",
      "progress: 670/2111\n",
      "progress: 680/2111\n",
      "progress: 690/2111\n",
      "progress: 700/2111\n",
      "progress: 710/2111\n",
      "progress: 720/2111\n",
      "progress: 730/2111\n",
      "progress: 740/2111\n",
      "progress: 750/2111\n",
      "progress: 760/2111\n",
      "progress: 770/2111\n",
      "progress: 780/2111\n",
      "progress: 790/2111\n",
      "progress: 800/2111\n",
      "progress: 810/2111\n",
      "progress: 820/2111\n",
      "progress: 830/2111\n",
      "progress: 840/2111\n",
      "progress: 850/2111\n",
      "progress: 860/2111\n",
      "progress: 870/2111\n",
      "progress: 880/2111\n",
      "progress: 890/2111\n",
      "progress: 900/2111\n",
      "progress: 910/2111\n",
      "progress: 920/2111\n",
      "progress: 930/2111\n",
      "progress: 940/2111\n",
      "progress: 950/2111\n",
      "progress: 960/2111\n",
      "progress: 970/2111\n",
      "progress: 980/2111\n",
      "progress: 990/2111\n",
      "progress: 1000/2111\n",
      "progress: 1010/2111\n",
      "progress: 1020/2111\n",
      "progress: 1030/2111\n",
      "progress: 1040/2111\n",
      "progress: 1050/2111\n",
      "progress: 1060/2111\n",
      "progress: 1070/2111\n",
      "progress: 1080/2111\n",
      "progress: 1090/2111\n",
      "progress: 1100/2111\n",
      "progress: 1110/2111\n",
      "progress: 1120/2111\n",
      "progress: 1130/2111\n",
      "progress: 1140/2111\n",
      "progress: 1150/2111\n",
      "progress: 1160/2111\n",
      "progress: 1170/2111\n",
      "progress: 1180/2111\n",
      "progress: 1190/2111\n",
      "progress: 1200/2111\n",
      "progress: 1210/2111\n",
      "progress: 1220/2111\n",
      "progress: 1230/2111\n",
      "progress: 1240/2111\n",
      "progress: 1250/2111\n",
      "progress: 1260/2111\n",
      "progress: 1270/2111\n",
      "progress: 1280/2111\n",
      "progress: 1290/2111\n",
      "progress: 1300/2111\n",
      "progress: 1310/2111\n",
      "progress: 1320/2111\n",
      "progress: 1330/2111\n",
      "progress: 1340/2111\n",
      "progress: 1350/2111\n",
      "progress: 1360/2111\n",
      "progress: 1370/2111\n",
      "progress: 1380/2111\n",
      "progress: 1390/2111\n",
      "progress: 1400/2111\n",
      "progress: 1410/2111\n",
      "progress: 1420/2111\n",
      "progress: 1430/2111\n",
      "progress: 1440/2111\n",
      "progress: 1450/2111\n",
      "progress: 1460/2111\n",
      "progress: 1470/2111\n",
      "progress: 1480/2111\n",
      "progress: 1490/2111\n",
      "progress: 1500/2111\n",
      "progress: 1510/2111\n",
      "progress: 1520/2111\n",
      "progress: 1530/2111\n",
      "progress: 1540/2111\n",
      "progress: 1550/2111\n",
      "progress: 1560/2111\n",
      "progress: 1570/2111\n",
      "progress: 1580/2111\n"
     ]
    },
    {
     "ename": "InvalidDicomError",
     "evalue": "File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDicomError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bf2976d63751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             mritopng.convert_file(data_pool_path + elem[0],  \n\u001b[0;32m---> 45\u001b[0;31m                                   output_dir + output_path + str(elem[1]) + \"/\" + elem[0] + \".png\")\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/jma/.local/lib/python3.6/site-packages/mritopng/__init__.py\u001b[0m in \u001b[0;36mconvert_file\u001b[0;34m(mri_file_path, png_file_path, auto_contrast)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mpng_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmri_to_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpng_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_contrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mpng_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/jma/.local/lib/python3.6/site-packages/mritopng/__init__.py\u001b[0m in \u001b[0;36mmri_to_png\u001b[0;34m(mri_file, png_file, do_auto_contrast)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimage_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_grayscale_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_auto_contrast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/jma/.local/lib/python3.6/site-packages/mritopng/__init__.py\u001b[0m in \u001b[0;36mextract_grayscale_image\u001b[0;34m(mri_file)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_grayscale_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Extracting data from the mri file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mplan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/jma/.local/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 850\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    851\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcaller_owns_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/jma/.local/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;31m# Read preamble (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preamble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m     \u001b[0;31m# Read any File Meta Information group (0002,eeee) elements (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mfile_meta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_file_meta_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/jma/.local/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_preamble\u001b[0;34m(fp, force)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"DICM\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         raise InvalidDicomError(\"File is missing DICOM File Meta Information \"\n\u001b[0m\u001b[1;32m    606\u001b[0m                                 \u001b[0;34m\"header or the 'DICM' prefix is missing from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                                 \"the header. Use force=True to force reading.\")\n",
      "\u001b[0;31mInvalidDicomError\u001b[0m: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading."
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import mritopng\n",
    "import os\n",
    "\n",
    "\n",
    "#####------ ADJUST SETTINGS BELOW ------#####\n",
    "\n",
    "log_path = \"./data/logs/\"\n",
    "data_pool_path = \"./data/data_pool_dicom/\"\n",
    "output_dir = \"./data/generated_sets/\"\n",
    "\n",
    "rater_log_paths = [\"ratings_ali.csv\", \"ratings_peter.csv\"]\n",
    "output_paths = [\"ali_labels/\", \"peter_labels/\"]\n",
    "\n",
    "\n",
    "#####------ ADJUST SETTINGS ABOVE ------#####\n",
    "\n",
    "\n",
    "for rater_log, output_path in zip(rater_log_paths, output_paths):\n",
    "    \n",
    "    print(\"using rater log: \" + rater_log)\n",
    "    print(\"outputting to: \" + output_dir + output_path)\n",
    "    \n",
    "    if os.path.exists(output_dir + output_path):\n",
    "        shutil.rmtree(output_dir + output_path)\n",
    "    os.mkdir(output_dir + output_path)\n",
    "\n",
    "    os.mkdir(output_dir + output_path + \"0/\")\n",
    "    os.mkdir(output_dir + output_path + \"1/\")\n",
    "    os.mkdir(output_dir + output_path + \"2/\")\n",
    "\n",
    "    ratings = get_ratings_list(log_path + rater_log)\n",
    "    \n",
    "    total_len = len(ratings)\n",
    "    count = 0\n",
    "    \n",
    "    for elem in ratings:\n",
    "\n",
    "        if (count % 10 == 0):\n",
    "            print(\"progress: \" + str(count) + \"/\" + str(total_len))\n",
    "\n",
    "\n",
    "        if (elem[1] != 100):\n",
    "            mritopng.convert_file(data_pool_path + elem[0],  \n",
    "                                  output_dir + output_path + str(elem[1]) + \"/\" + elem[0] + \".png\")\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "# above seems to take care of contrast as well\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Train, Eval, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data_utility\n",
    "import shutil\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#####------ ADJUST SETTINGS BELOW ------#####\n",
    "\n",
    "data_root = \"./data/original_data/data_relabeled_undersampled_png/\"\n",
    "output_folter = \"./data/generated_splits/undersampled/\"\n",
    "split_ratios = [0.7, 0.1, 0.2]\n",
    "\n",
    "#####------ ADJUST SETTINGS ABOVE ------#####\n",
    "\n",
    "image_paths = load_data_utility.load_image_paths(data_root)\n",
    "\n",
    "print(image_paths[:5])\n",
    "\n",
    "train_paths, eval_paths, test_paths = load_data_utility.split(image_paths, split=split_ratios, seed=777)\n",
    "\n",
    "def get_label(path):\n",
    "    \n",
    "    path_location = pathlib.Path(path)\n",
    "    \n",
    "    str1 = str(path_location.parents[0])\n",
    "    str2 = str(path_location.parents[1])\n",
    "    \n",
    "    \n",
    "    retval = str1.replace(str2, '')\n",
    "    retval = retval.replace(\"/\", '')\n",
    "    \n",
    "    return retval\n",
    "\n",
    "\n",
    "print(train_paths[0])\n",
    "print(get_label(train_paths[0]))\n",
    "\n",
    "if os.path.exists(output_folter):\n",
    "    shutil.rmtree(output_folter)\n",
    "    \n",
    "os.mkdir(output_folter)\n",
    "os.mkdir(output_folter + \"train/\")\n",
    "os.mkdir(output_folter + \"eval/\")\n",
    "os.mkdir(output_folter + \"test/\")\n",
    "os.mkdir(output_folter + \"train/0/\")\n",
    "os.mkdir(output_folter + \"train/1/\")\n",
    "os.mkdir(output_folter + \"train/2/\")\n",
    "os.mkdir(output_folter + \"eval/0/\")\n",
    "os.mkdir(output_folter + \"eval/1/\")\n",
    "os.mkdir(output_folter + \"eval/2/\")\n",
    "os.mkdir(output_folter + \"test/0/\")\n",
    "os.mkdir(output_folter + \"test/1/\")\n",
    "os.mkdir(output_folter + \"test/2/\")\n",
    "\n",
    "\n",
    "for pngfile in train_paths:\n",
    "    shutil.copy(pngfile, output_folter + \"train/\" + get_label(pngfile) + \"/\" )\n",
    "\n",
    "for pngfile in eval_paths:\n",
    "    shutil.copy(pngfile, output_folter + \"eval/\" + get_label(pngfile) + \"/\" )\n",
    "    \n",
    "for pngfile in test_paths:\n",
    "    shutil.copy(pngfile, output_folter + \"test/\" + get_label(pngfile) + \"/\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "# load an array of image paths\n",
    "def load_sorted_paths(path):\n",
    "    \n",
    "    data_root = pathlib.Path(path)\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    for child in data_root.iterdir():\n",
    "        if (child.is_dir() and child.name != \".DS_Store\"):\n",
    "            print(child)\n",
    "            \n",
    "            subdir_paths = list(child.glob('**/*'))\n",
    "            subdir_paths = [str(path) for path in subdir_paths if path.name != \".DS_Store\"]\n",
    "        \n",
    "            paths.append(subdir_paths)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "\n",
    "# load an array of image paths\n",
    "def load_dir_paths(path):\n",
    "    \n",
    "    data_root = pathlib.Path(path)\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    for child in data_root.iterdir():\n",
    "        if (child.name != \".DS_Store\"):\n",
    "         \n",
    "            paths.append(str(child))\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inserting Noisy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import synthetic_motion_utility as synth\n",
    "import imageio\n",
    "\n",
    "input_data_dir = \"./data/generated_splits/train_set_balanced/train/1/\"\n",
    "output_data_dir = \"./data/generated_splits/train_set_balanced/train/0/\"\n",
    "\n",
    "all_image_paths = load_dir_paths(input_data_dir)\n",
    "\n",
    "num_synthetic = 400\n",
    "counter = 0\n",
    "\n",
    "random.seed(a=777)\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "while counter < num_synthetic:\n",
    "    \n",
    "    im = imageio.imread(all_image_paths[counter])\n",
    "    \n",
    "    im = synth.add_motion_artifact(im, seed=counter)\n",
    "    \n",
    "    imageio.imwrite(output_data_dir + \"synthetic_\" + str(counter) + \".png\", im)\n",
    "    \n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Oversampling 2-Label Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "\n",
    "data_root_2 = \"./data/generated_splits/train_set_balanced/train/2/\"\n",
    "image_paths_2 = load_dir_paths(data_root_2)\n",
    "\n",
    "print(image_paths_2[:10])\n",
    "\n",
    "for filename in glob.glob(data_root_2 + \"duplicate*\"):\n",
    "    os.remove(filename) \n",
    "\n",
    "counter = 0\n",
    "for pngfile in image_paths_2:\n",
    "    shutil.copy(pngfile, data_root_2 + \"duplicate_\" +  str(counter) + \".png\" )\n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Undersampling Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(a=777)\n",
    "\n",
    "data_root = \"./data/original_data/data_relabeled_undersampled_png/\"\n",
    "\n",
    "data_root = data_root + \"1/\"\n",
    "\n",
    "paths_in_dir = load_dir_paths(data_root)\n",
    "\n",
    "random.shuffle(paths_in_dir)\n",
    "\n",
    "print(paths_in_dir[:10])\n",
    "\n",
    "random.seed(a=777)\n",
    "\n",
    "for path in paths_in_dir:\n",
    "    \n",
    "    if (random.choice([True, False])):\n",
    "        print(\"removing: \" + path)\n",
    "        os.remove(path)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
