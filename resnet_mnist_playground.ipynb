{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T19:56:33.789720Z",
     "start_time": "2019-07-18T19:56:33.763796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tf_contrib\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from cleverhans.loss import SNNLCrossEntropy\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# which GPU to be used (0 is RTX, 1 or 2 are either of the Titan Xps)\n",
    "gpu = \"/GPU:0\"\n",
    "\n",
    "AUTOTUNE = tf.contrib.data.AUTOTUNE\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.allow_growth = True\n",
    "session_config.allow_soft_placement = True\n",
    "\n",
    "# session_config.log_device_placement = True\n",
    "tf.keras.backend.set_session(tf.Session(config=session_config))\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T19:56:34.003605Z",
     "start_time": "2019-07-18T19:56:33.864780Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Xavier : tf_contrib.layers.xavier_initializer()\n",
    "# He : tf_contrib.layers.variance_scaling_initializer()\n",
    "# Normal : tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
    "# l2_decay : tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "weight_init = tf_contrib.layers.variance_scaling_initializer()\n",
    "weight_regularizer = tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Layer\n",
    "##################################################################################\n",
    "\n",
    "def conv(x, channels, kernel=4, stride=2, padding='SAME', use_bias=True, scope='conv_0'):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = tf.layers.conv2d(inputs=x, filters=channels,\n",
    "                             kernel_size=kernel, kernel_initializer=weight_init,\n",
    "                             kernel_regularizer=weight_regularizer,\n",
    "                             strides=stride, use_bias=use_bias, padding=padding)\n",
    "\n",
    "        return x\n",
    "\n",
    "def fully_connected(x, units, use_bias=True, scope='fully_0'):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = flatten(x)\n",
    "        x = tf.layers.dense(x, units=units, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resblock(x_init, channels, kernel=3, is_training=True, use_bias=True, downsample=False, scope='resblock') :\n",
    "    with tf.variable_scope(scope) :\n",
    "\n",
    "        x = batch_norm(x_init, is_training, scope='batch_norm_0')\n",
    "        x = relu(x)\n",
    "\n",
    "        if downsample :\n",
    "            x = conv(x, channels, kernel=kernel, stride=2, use_bias=use_bias, scope='conv_0')\n",
    "            x_init = conv(x_init, channels, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        else :\n",
    "            x = conv(x, channels, kernel=kernel, stride=1, use_bias=use_bias, scope='conv_0')\n",
    "\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_1')\n",
    "        x = relu(x)\n",
    "        x = conv(x, channels, kernel=kernel, stride=1, use_bias=use_bias, scope='conv_1')\n",
    "\n",
    "        return x + x_init\n",
    "\n",
    "def bottle_resblock(x_init, channels, is_training=True, use_bias=True, downsample=False, scope='bottle_resblock') :\n",
    "    with tf.variable_scope(scope) :\n",
    "        x = batch_norm(x_init, is_training, scope='batch_norm_1x1_front')\n",
    "        shortcut = relu(x)\n",
    "\n",
    "        x = conv(shortcut, channels, kernel=1, stride=1, use_bias=use_bias, scope='conv_1x1_front')\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_3x3')\n",
    "        x = relu(x)\n",
    "\n",
    "        if downsample :\n",
    "            x = conv(x, channels, kernel=3, stride=2, use_bias=use_bias, scope='conv_0')\n",
    "            shortcut = conv(shortcut, channels*4, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        else :\n",
    "            x = conv(x, channels, kernel=3, stride=1, use_bias=use_bias, scope='conv_0')\n",
    "            shortcut = conv(shortcut, channels * 4, kernel=1, stride=1, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_1x1_back')\n",
    "        x = relu(x)\n",
    "        x = conv(x, channels*4, kernel=1, stride=1, use_bias=use_bias, scope='conv_1x1_back')\n",
    "\n",
    "        return x + shortcut\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Sampling\n",
    "##################################################################################\n",
    "\n",
    "def flatten(x) :\n",
    "    return tf.layers.flatten(x)\n",
    "\n",
    "def global_avg_pooling(x):\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "    return gap\n",
    "\n",
    "def avg_pooling(x) :\n",
    "    return tf.layers.average_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "def max_pooling(x) :\n",
    "    return tf.layers.max_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Activation function\n",
    "##################################################################################\n",
    "\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Normalization function\n",
    "##################################################################################\n",
    "\n",
    "def batch_norm(x, is_training=True, scope='batch_norm'):\n",
    "    return tf_contrib.layers.batch_norm(x,\n",
    "                                        decay=0.9, epsilon=1e-05,\n",
    "                                        center=True, scale=True, updates_collections=None,\n",
    "                                        is_training=is_training, scope=scope)\n",
    "\n",
    "##################################################################################\n",
    "# Loss function\n",
    "##################################################################################\n",
    "\n",
    "def classification_loss(logit, label) :\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logit))\n",
    "    prediction = tf.equal(tf.argmax(logit, -1), tf.argmax(label, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:13:28.385392Z",
     "start_time": "2019-06-25T17:11:53.702Z"
    }
   },
   "source": [
    "# ResNet-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T19:56:34.100526Z",
     "start_time": "2019-07-18T19:56:34.005259Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# ResNet-10 architecture\n",
    "def resnet10_network(x, labels, conv_kernel=7, resblock_kernel=3, num_channels=4, n_classes=num_classes, reuse = False, is_training = True):\n",
    "    with tf.variable_scope('Resnet-10', reuse = reuse), tf.device(gpu):\n",
    "    \n",
    "        \n",
    "        print(x)\n",
    "        \n",
    "        x = tf.reshape(x, [-1,28,28,1])\n",
    "        \n",
    "        # channels\n",
    "        x = conv(x, num_channels, kernel=conv_kernel, stride=1, padding='SAME')\n",
    "\n",
    "        \n",
    "        \n",
    "        x = resblock(x, channels=num_channels, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock0_id1')\n",
    "            \n",
    "        x = resblock(x, channels=num_channels * 2, kernel=resblock_kernel, is_training=is_training, downsample=True, scope='resblock_conv1')\n",
    "\n",
    "        x = resblock(x, channels=num_channels * 2, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock1_id1')\n",
    "        \n",
    "        x = resblock(x, channels=num_channels * 4, kernel=resblock_kernel, is_training=is_training, downsample=True, scope='resblock_conv2')\n",
    "\n",
    "        x = resblock(x, channels=num_channels * 4, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock2_id1')\n",
    "        \n",
    "        x = batch_norm(x, is_training, scope='batch_norm')\n",
    "        x = relu(x)\n",
    "        \n",
    "        print(x)\n",
    "\n",
    "        x = fully_connected(x, units=n_classes, scope='logit')\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def resnet10_model_fn(features, labels, mode, conv_kernel=7, resblock_kernel=3, num_channels=4):\n",
    "    with tf.device(gpu):\n",
    "        \n",
    "        logits_train = resnet10_network(features, conv_kernel=conv_kernel, resblock_kernel=resblock_kernel, num_channels=num_channels, n_classes=num_classes, reuse=False, is_training=True)\n",
    "        logits_test = resnet10_network(features, conv_kernel=conv_kernel, resblock_kernel=resblock_kernel, num_channels=num_channels, n_classes=num_classes, reuse=True, is_training=False)\n",
    "        # find highest val (prediction)\n",
    "        pred_classes = tf.arg_max(logits_test, dimension=1)\n",
    "\n",
    "        # if in prediction mode\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            \n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "        \n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        \n",
    "        # loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "        loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "\n",
    "        \n",
    "        loss_op = loss_op + SNNLCrossEntropy.optimized_temp_SNNL(logits_train, labels, 50.0, True)\n",
    "    \n",
    "        \n",
    "        tf.summary.scalar(\"loss\", loss_op)\n",
    "        \n",
    "        print(loss_op)\n",
    "        \n",
    "        # Evaluate model accuracy\n",
    "        acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "        tf.summary.scalar(\"training_accuracy\", acc_op[1])\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "            \n",
    "            # the different ops for training, evaluating, ...\n",
    "            estim_specs = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=pred_classes,\n",
    "                loss=loss_op,\n",
    "                train_op=train_op,\n",
    "                eval_metric_ops={'accuracy': acc_op},\n",
    "            ) \n",
    "\n",
    "            return estim_specs\n",
    "        \n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "   \n",
    "            # the different ops for training, evaluating, ...\n",
    "            estim_specs = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=pred_classes,\n",
    "                loss=loss_op,\n",
    "                eval_metric_ops={'accuracy': acc_op},\n",
    "            ) \n",
    "\n",
    "            return estim_specs\n",
    "       \n",
    "        else:\n",
    "            print(\"Something went wrong.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T19:56:36.643736Z",
     "start_time": "2019-07-18T19:56:35.839822Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-de6664ebf032>:24: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/resnet_mnist_snnl/with_snnl_loss/', '_tf_random_seed': 777, '_save_summary_steps': 50, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 5, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 20, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe8bd0fdf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 5.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "b_size = 64\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "random_seed = 777\n",
    "\n",
    "num_steps = 4000\n",
    "\n",
    "tf.summary.FileWriterCache.clear()\n",
    "        \n",
    "config = tf.estimator.RunConfig(\n",
    "    log_step_count_steps= 20,\n",
    "    save_summary_steps= 50,\n",
    "    save_checkpoints_secs= 5,\n",
    "    model_dir=\"/tmp/resnet_mnist_snnl/with_snnl_loss/\",\n",
    "    tf_random_seed=random_seed,\n",
    "    session_config=session_config)\n",
    "\n",
    "model_fn = lambda features, labels, mode: resnet10_model_fn(features, labels, mode, conv_kernel=7, num_channels=8)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "# Define the input function for training\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=mnist.train.images, y=mnist.train.labels, batch_size=b_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=mnist.test.images, y=mnist.test.labels, batch_size=b_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=model_fn, config=config)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=num_steps)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, throttle_secs=5)\n",
    "\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
