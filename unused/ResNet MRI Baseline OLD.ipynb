{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-26T18:40:46.722Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "import tensorflow.contrib as tf_contrib\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "\n",
    "import random\n",
    "\n",
    "import pylab\n",
    "import tfplot\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tfx\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "%matplotlib inline\n",
    "\n",
    "from cleverhans.loss import SNNLCrossEntropy\n",
    "\n",
    "# which GPU to be used (0 is RTX, 1 or 2 are either of the Titan Xps)\n",
    "gpu = \"/GPU:0\"\n",
    "\n",
    "AUTOTUNE = tf.contrib.data.AUTOTUNE\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.allow_growth = True\n",
    "session_config.allow_soft_placement = True\n",
    "\n",
    "# session_config.log_device_placement = True\n",
    "tf.keras.backend.set_session(tf.Session(config=session_config))\n",
    "\n",
    "# make sure tensorflow-gpu is being used\n",
    "print(tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:27:21.062806Z",
     "start_time": "2019-07-26T06:27:20.934249Z"
    },
    "code_folding": [
     55
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Xavier : tf_contrib.layers.xavier_initializer()\n",
    "# He : tf_contrib.layers.variance_scaling_initializer()\n",
    "# Normal : tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
    "# l2_decay : tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "weight_init = tf_contrib.layers.variance_scaling_initializer()\n",
    "weight_regularizer = tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Layer\n",
    "##################################################################################\n",
    "\n",
    "def conv(x, channels, kernel=4, stride=2, padding='SAME', use_bias=True, scope='conv_0'):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = tf.layers.conv2d(inputs=x, filters=channels,\n",
    "                             kernel_size=kernel, kernel_initializer=weight_init,\n",
    "                             kernel_regularizer=weight_regularizer,\n",
    "                             strides=stride, use_bias=use_bias, padding=padding)\n",
    "\n",
    "        return x\n",
    "\n",
    "def fully_connected(x, units, use_bias=True, scope='fully_0'):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = flatten(x)\n",
    "        x = tf.layers.dense(x, units=units, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resblock(x_init, channels, kernel=3, is_training=True, use_bias=True, downsample=False, scope='resblock') :\n",
    "    with tf.variable_scope(scope) :\n",
    "\n",
    "        x = batch_norm(x_init, is_training, scope='batch_norm_0')\n",
    "        x = relu(x)\n",
    "\n",
    "        if downsample :\n",
    "            x = conv(x, channels, kernel=kernel, stride=2, use_bias=use_bias, scope='conv_0')\n",
    "            x_init = conv(x_init, channels, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        else :\n",
    "            x = conv(x, channels, kernel=kernel, stride=1, use_bias=use_bias, scope='conv_0')\n",
    "\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_1')\n",
    "        x = relu(x)\n",
    "        x = conv(x, channels, kernel=kernel, stride=1, use_bias=use_bias, scope='conv_1')\n",
    "\n",
    "        return x + x_init\n",
    "\n",
    "def bottle_resblock(x_init, channels, is_training=True, use_bias=True, downsample=False, scope='bottle_resblock') :\n",
    "    with tf.variable_scope(scope) :\n",
    "        x = batch_norm(x_init, is_training, scope='batch_norm_1x1_front')\n",
    "        shortcut = relu(x)\n",
    "\n",
    "        x = conv(shortcut, channels, kernel=1, stride=1, use_bias=use_bias, scope='conv_1x1_front')\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_3x3')\n",
    "        x = relu(x)\n",
    "\n",
    "        if downsample :\n",
    "            x = conv(x, channels, kernel=3, stride=2, use_bias=use_bias, scope='conv_0')\n",
    "            shortcut = conv(shortcut, channels*4, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        else :\n",
    "            x = conv(x, channels, kernel=3, stride=1, use_bias=use_bias, scope='conv_0')\n",
    "            shortcut = conv(shortcut, channels * 4, kernel=1, stride=1, use_bias=use_bias, scope='conv_init')\n",
    "\n",
    "        x = batch_norm(x, is_training, scope='batch_norm_1x1_back')\n",
    "        x = relu(x)\n",
    "        x = conv(x, channels*4, kernel=1, stride=1, use_bias=use_bias, scope='conv_1x1_back')\n",
    "\n",
    "        return x + shortcut\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Sampling\n",
    "##################################################################################\n",
    "\n",
    "def flatten(x) :\n",
    "    return tf.layers.flatten(x)\n",
    "\n",
    "def global_avg_pooling(x):\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "    return gap\n",
    "\n",
    "def avg_pooling(x) :\n",
    "    return tf.layers.average_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "def max_pooling(x) :\n",
    "    return tf.layers.max_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Activation function\n",
    "##################################################################################\n",
    "\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Normalization function\n",
    "##################################################################################\n",
    "\n",
    "def batch_norm(x, is_training=True, scope='batch_norm'):\n",
    "    return tf_contrib.layers.batch_norm(x,\n",
    "                                        decay=0.9, epsilon=1e-05,\n",
    "                                        center=True, scale=True, updates_collections=None,\n",
    "                                        is_training=is_training, scope=scope)\n",
    "\n",
    "##################################################################################\n",
    "# Loss function\n",
    "##################################################################################\n",
    "\n",
    "def classification_loss(logit, label) :\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logit))\n",
    "    prediction = tf.equal(tf.argmax(logit, -1), tf.argmax(label, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:27:21.077315Z",
     "start_time": "2019-07-26T06:27:21.064180Z"
    },
    "code_folding": [
     0,
     2,
     15
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def rotate(image):\n",
    "    \n",
    "    return tf.image.rot90(image, tf.random_uniform(shape=[], minval=0, maxval=4, \n",
    "                                               dtype=tf.int32))\n",
    "\n",
    "def flip(image):\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def crop(image, range_start=0.8, range_end=1.0):\n",
    "    \n",
    "    image = tf.image.central_crop(image, central_fraction=random.uniform(range_start, range_end))\n",
    "    image = tf.image.resize_images(image,tf.constant([512, 512]))\n",
    "    return image\n",
    "\n",
    "def translate(image,  x_max=75, y_max=75):\n",
    "    \n",
    "    return tf.contrib.image.translate(image, translations=[random.uniform(-1 * x_max, x_max), \n",
    "                                                           random.uniform(-1 * y_max, y_max)])\n",
    "\n",
    "def augment_image(image):\n",
    "                       \n",
    "    image = rotate(image)\n",
    "    image = flip(image)\n",
    "    \n",
    "    image = translate(image)\n",
    "    image = crop(image)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:27:21.223329Z",
     "start_time": "2019-07-26T06:27:21.136949Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# load an array of image paths\n",
    "def load_image_paths(path):\n",
    "    \n",
    "    data_root = pathlib.Path(path)\n",
    "    \n",
    "    # create a list of every file and its label index\n",
    "    all_image_paths = list(data_root.glob('*/*'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]\n",
    "    \n",
    "    return all_image_paths\n",
    "\n",
    "# randomly shuffle train and test values and split based on parameters\n",
    "def split(image_paths, split=[0.6,0.2,0.2], seed=777):\n",
    "    random.Random(seed).shuffle(image_paths)\n",
    "    \n",
    "    boundary1 = int(len(image_paths) * split[0])\n",
    "    boundary2 = int(len(image_paths) * (split[0]+split[1]))\n",
    "    \n",
    "    train = image_paths[:boundary1]\n",
    "    evaluate = image_paths[boundary1: boundary2]\n",
    "    test = image_paths[boundary2:]\n",
    "    \n",
    "    return train, evaluate, test\n",
    "\n",
    "# preprocessing functions\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, shape=[512,512])\n",
    "    image = tf.div(\n",
    "       tf.subtract(\n",
    "          image, \n",
    "          tf.reduce_min(image)\n",
    "       ), \n",
    "       tf.subtract(\n",
    "          tf.reduce_max(image), \n",
    "          tf.reduce_min(image)\n",
    "       )\n",
    "    )\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path, training=True):\n",
    "    image = tf.read_file(path)\n",
    "    image = preprocess_image(image)\n",
    "    \n",
    "    if (training):\n",
    "        image = augment_image(image[:,:,None])\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load(path, image_paths, training=True, batch_size=64, shuffle=True, drop_remainder=False):\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        # data root\n",
    "        data_root = pathlib.Path(path)\n",
    "\n",
    "        # return label names\n",
    "        label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "\n",
    "        # assign index to label\n",
    "        label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "        # array of all labels corresponding to image_paths\n",
    "        all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                            for path in image_paths]\n",
    "\n",
    "        # make path dataset\n",
    "        path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "\n",
    "        # get image tensors by mapping function over the path dataset\n",
    "        image_ds = path_ds.map(lambda path : load_and_preprocess_image(path, training=training))\n",
    "\n",
    "        # create label dataset\n",
    "        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
    "\n",
    "        # zip together image and label dataset into dataset of tuples for\n",
    "        # estimator input\n",
    "        image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "        # Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "        # completely shuffled\n",
    "        \n",
    "        image_label_ds = image_label_ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "        \n",
    "        if (training):\n",
    "            print(\"shuffling and repeating b/c training flag set\")\n",
    "\n",
    "            image_label_ds = image_label_ds.repeat()\n",
    "        else:\n",
    "            image_label_ds = image_label_ds.repeat(count=1)\n",
    "        \n",
    "        \n",
    "        if (shuffle):\n",
    "            image_label_ds = image_label_ds.shuffle(buffer_size = len(image_paths))\n",
    "            \n",
    "        # `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "        image_label_ds = image_label_ds.prefetch(6)\n",
    "       \n",
    "        \n",
    "        return image_label_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:13:28.385392Z",
     "start_time": "2019-06-25T17:11:53.702Z"
    }
   },
   "source": [
    "# ResNet-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:27:21.549924Z",
     "start_time": "2019-07-26T06:27:21.304966Z"
    },
    "code_folding": [
     0,
     14,
     75,
     155,
     192
    ]
   },
   "outputs": [],
   "source": [
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \n",
    "    print(\"running tsne\")\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "    print(X)\n",
    "    \n",
    "    # Initialize variables\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    max_iter = 1000\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    Z = [Y[:,0], Y[:,1]]\n",
    "            \n",
    "    # Return solution\n",
    "    return Z\n",
    "    \n",
    "class TF_PCA:\n",
    "\n",
    "    def __init__(self, data, target, dtype=tf.float32):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def fit(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.X = tf.placeholder(self.dtype, shape=self.data.shape)\n",
    "            # Perform SVD\n",
    "            singular_values, u, _ = tf.svd(self.X)\n",
    "            # Create sigma matrix\n",
    "            sigma = tf.diag(singular_values)\n",
    "        with tf.Session(graph=self.graph) as session:\n",
    "            self.u, self.singular_values, self.sigma = session.run([u, singular_values, sigma],\n",
    "                                                                   feed_dict={self.X: self.data})\n",
    "\n",
    "    def reduce(self, n_dimensions=None, keep_info=None):\n",
    "        if keep_info:\n",
    "            # Normalize singular values\n",
    "            normalized_singular_values = self.singular_values / sum(self.singular_values)\n",
    "            # Create the aggregated ladder of kept information per dimension\n",
    "            ladder = np.cumsum(normalized_singular_values)\n",
    "            # Get the first index which is above the given information threshold\n",
    "            index = next(idx for idx, value in enumerate(ladder) if value >= keep_info) + 1\n",
    "            n_dimensions = index\n",
    "        with self.graph.as_default():\n",
    "            # Cut out the relevant part from sigma\n",
    "            sigma = tf.slice(self.sigma, [0, 0], [self.data.shape[1], n_dimensions])\n",
    "            # PCA\n",
    "            pca = tf.matmul(self.u, sigma)\n",
    "        with tf.Session(graph=self.graph) as session:\n",
    "            return session.run(pca, feed_dict={self.X: self.data})   \n",
    "        \n",
    "def pca_tf(X_tensor, Y_tensor):\n",
    "    \n",
    "    my_pca = TF_PCA(X_tensor, Y_tensor)\n",
    "    my_pca.fit()\n",
    "    \n",
    "    result = my_pca.reduce(n_dimensions=2)\n",
    "    print(result.shape)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:34:12.532517Z",
     "start_time": "2019-07-26T06:34:12.394143Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "# ResNet-10 architecture\n",
    "def resnet10_network(x, conv_kernel=7, resblock_kernel=3, num_channels=4, n_classes=num_classes, reuse = False, is_training = True):\n",
    "    with tf.variable_scope('Resnet-10', reuse = reuse), tf.device(gpu):\n",
    "        \n",
    "        x = tf.reshape(x, shape=[-1, 512, 512, 1])\n",
    "        # channels\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = conv(x, num_channels, kernel=conv_kernel, stride=1, padding='SAME')\n",
    "        \n",
    "        x = resblock(x, channels=num_channels, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock_id0')\n",
    "            \n",
    "   \n",
    "        x = resblock(x, channels=num_channels * 2, kernel=resblock_kernel, is_training=is_training, \n",
    "                     downsample=True, scope='resblock_conv0')\n",
    "\n",
    "    \n",
    "        \n",
    "        x = resblock(x, channels=num_channels * 2, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock_id1')\n",
    "        \n",
    "  \n",
    "        \n",
    "        x = resblock(x, channels=num_channels * 4, kernel=resblock_kernel, is_training=is_training, \n",
    "                     downsample=True, scope='resblock_conv1')\n",
    "\n",
    "    \n",
    "        \n",
    "        x = resblock(x, channels=num_channels * 4, kernel=resblock_kernel, is_training=is_training, \n",
    "                      downsample=False, scope='resblock_id2')\n",
    "        \n",
    "      \n",
    "        \n",
    "        x = batch_norm(x, is_training, scope='batch_norm')\n",
    "        x = relu(x)\n",
    "        \n",
    "        x_pre_logits = flatten(x)\n",
    "\n",
    "        x = fully_connected(x, num_classes)\n",
    "        \n",
    "        return x, x_pre_logits\n",
    "\n",
    "    \n",
    "def resnet10_model_fn(features, labels, mode, conv_kernel=7, resblock_kernel=3, num_channels=4, snnl_weight=0.05,\n",
    "                      log=True):\n",
    "    with tf.device(gpu):\n",
    "\n",
    "        print(\"in gpu part\")\n",
    "        logits_train, pre_logits_train = resnet10_network(features,\n",
    "                                                          conv_kernel=conv_kernel,\n",
    "                                                          resblock_kernel=resblock_kernel,\n",
    "                                                          num_channels=num_channels,\n",
    "                                                          n_classes=num_classes,\n",
    "                                                          reuse=False,\n",
    "                                                          is_training=True)\n",
    "\n",
    "        logits_test, pre_logits_test = resnet10_network(features,\n",
    "                                                        conv_kernel=conv_kernel,\n",
    "                                                        resblock_kernel=resblock_kernel,\n",
    "                                                        num_channels=num_channels,\n",
    "                                                        n_classes=num_classes,\n",
    "                                                        reuse=True,\n",
    "                                                        is_training=False)\n",
    "\n",
    "        pred_classes = tf.arg_max(logits_test, dimension=1)\n",
    "\n",
    "        # PREDICT MODE\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=pred_classes)\n",
    "\n",
    "\n",
    "        loss_op = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "\n",
    "        loss_op = (1.0 - snnl_weight) * loss_op + snnl_weight * SNNLCrossEntropy.optimized_temp_SNNL(pre_logits_train,\n",
    "                                                                                                     labels, 20.0, True)\n",
    "        acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        tf.summary.scalar(\"loss\", loss_op)\n",
    "        tf.summary.scalar(\"accuracy\", acc_op[1])\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "            # the different ops for training, evaluating, ...\n",
    "            estim_specs = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=pred_classes,\n",
    "                loss=loss_op,\n",
    "                train_op=train_op,\n",
    "                eval_metric_ops={'accuracy': acc_op}\n",
    "            )\n",
    "\n",
    "            return estim_specs\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     for var in tf.trainable_variables():\n",
    "#         print(var.name)\n",
    "    \n",
    "    \n",
    "        conv0_weights = [v for v in tf.global_variables() if v.name == \"Resnet-10/conv_0/conv2d/kernel:0\"][0]\n",
    "        print(conv0_weights)\n",
    "\n",
    "\n",
    "\n",
    "        plot_op = plot_conv_weights(conv0_weights)\n",
    "\n",
    "        print(plot_op)\n",
    "        plot_op_expanded = tf.expand_dims(plot_op, 0)\n",
    "        tf.summary.image(\"conv_0_weight_plots\", plot_op_expanded)\n",
    "\n",
    "        eval_summary_hook = tf.train.SummarySaverHook(\n",
    "            save_steps=1,\n",
    "            output_dir=model_path + \"/eval_images\",\n",
    "            summary_op=tf.summary.merge_all())\n",
    "        # Add it to the evaluation_hook list\n",
    "        evaluation_hooks = []\n",
    "        evaluation_hooks.append(eval_summary_hook)\n",
    "\n",
    "        # the different ops for training, evaluating, ...\n",
    "        estim_specs = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss_op,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={'accuracy': acc_op},\n",
    "            evaluation_hooks=evaluation_hooks\n",
    "        )\n",
    "\n",
    "        return estim_specs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:28:06.287775Z",
     "start_time": "2019-07-26T06:28:06.239992Z"
    },
    "code_folding": [
     0,
     70
    ]
   },
   "outputs": [],
   "source": [
    "def prime_powers(n):\n",
    "    \"\"\"\n",
    "    Compute the factors of a positive integer\n",
    "    Algorithm from https://rosettacode.org/wiki/Factors_of_an_integer#Python\n",
    "    :param n: int\n",
    "    :return: set\n",
    "    \"\"\"\n",
    "    factors = set()\n",
    "    for x in range(1, int(np.sqrt(n)) + 1):\n",
    "        if n % x == 0:\n",
    "            factors.add(int(x))\n",
    "            factors.add(int(n // x))\n",
    "    return sorted(factors)\n",
    "\n",
    "def get_grid_dim(x):\n",
    "    \"\"\"\n",
    "    Transforms x into product of two integers\n",
    "    :param x: int\n",
    "    :return: two ints\n",
    "    \"\"\"\n",
    "    factors = prime_powers(x)\n",
    "    if len(factors) % 2 == 0:\n",
    "        i = int(len(factors) / 2)\n",
    "        return factors[i], factors[i - 1]\n",
    "\n",
    "    i = len(factors) // 2\n",
    "    return factors[i], factors[i]\n",
    "\n",
    "@tfplot.wrap\n",
    "def plot_conv_weights(weights, channels_all=True,):\n",
    "    \"\"\"\n",
    "    Plots convolutional filters\n",
    "    :param weights: numpy array of rank 4\n",
    "    :param channels_all: boolean, optional\n",
    "\n",
    "    \"\"\"\n",
    "    w_min = np.min(weights)\n",
    "    w_max = np.max(weights)\n",
    "\n",
    "    channels = [0]\n",
    "    # make a list of channels if all are plotted\n",
    "    if channels_all:\n",
    "        channels = range(weights.shape[2])\n",
    "\n",
    "    # get number of convolutional filters\n",
    "    num_filters = weights.shape[3]\n",
    "\n",
    "    # get number of grid rows and columns\n",
    "    grid_r, grid_c = get_grid_dim(num_filters)\n",
    "\n",
    "    print(grid_r)\n",
    "    print(grid_c)\n",
    "    \n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(min([grid_r, grid_c]), max([grid_r, grid_c]))\n",
    "\n",
    "    # iterate channels\n",
    "    for channel in channels:\n",
    "        # iterate filters inside every channel\n",
    "        for l, ax in enumerate(axes.flat):\n",
    "            # get a single filter\n",
    "            img = weights[:, :, channel, l]\n",
    "            # put it on the grid\n",
    "            ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n",
    "            # remove any labels from the axes\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def pca(X, num_observations=64, n_dimensions = 50):\n",
    "    singular_values, u, _ = tf.svd(X)\n",
    "    sigma = tf.diag(singular_values)\n",
    "    print(sigma)\n",
    "    \n",
    "    sigma = tf.slice(sigma, [0, 0], [num_observations, n_dimensions])\n",
    "    \n",
    "    pca = tf.matmul(u, sigma)\n",
    "    pca = tf.transpose(pca)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-26T06:34:19.902Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jma/model/resnet10_kernel_plots/kernel7_filter4_snnl0.0/\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/data/jma/model/resnet10_kernel_plots/kernel7_filter4_snnl0.0/', '_tf_random_seed': 777, '_save_summary_steps': 50, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 20, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2a74205f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 120.\n",
      "shuffling and repeating b/c training flag set\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "in gpu part\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /data/jma/model/resnet10_kernel_plots/kernel7_filter4_snnl0.0/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "b_size = 32\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "random_seed = 777\n",
    "\n",
    "num_steps = 10000\n",
    "\n",
    "resnet10_checkpoint_path_base = \"/data/jma/model/resnet10_kernel_plots/\"\n",
    "\n",
    "# kernel_sizes = [7, 9, 10, 11, 13]\n",
    "# filter_sizes = [10]\n",
    "# snnl_weights = [0.0]\n",
    "\n",
    "kernel_sizes = [7, 9, 5]\n",
    "filter_sizes = [4]\n",
    "snnl_weights = [0.0, 0.05, 0.1, 0.2]\n",
    "\n",
    "data_root = \"./data_3classes/\"\n",
    "\n",
    "image_paths = load_image_paths(data_root)\n",
    "train_paths, eval_paths, test_paths = split(image_paths, seed=random_seed)\n",
    "\n",
    "train_input_fn = lambda : load(data_root, train_paths, training=True, batch_size=32, shuffle=True)\n",
    "eval_input_fn = lambda : load(data_root, eval_paths, training=False, batch_size=32, shuffle=False)\n",
    "test_input_fn = lambda : load(data_root, test_paths, training=False, shuffle=False)\n",
    "\n",
    "for filter_size in filter_sizes:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        \n",
    "        for snnl_weight in snnl_weights:\n",
    "            tf.summary.FileWriterCache.clear()\n",
    " \n",
    "            model_path = resnet10_checkpoint_path_base + \"kernel\" + str(kernel_size) + \"_filter\" + str(filter_size) + \"_snnl\" + str(snnl_weight)+\"/\"\n",
    "            print(model_path)\n",
    "\n",
    "            config = tf.estimator.RunConfig(\n",
    "                log_step_count_steps= 20,\n",
    "                save_summary_steps= 50,\n",
    "                save_checkpoints_secs= 120,\n",
    "                model_dir=model_path,\n",
    "                tf_random_seed=random_seed,\n",
    "                session_config=session_config)\n",
    "\n",
    "            model_fn = lambda features, labels, mode: resnet10_model_fn(features, labels, mode, \n",
    "                                                                        conv_kernel=kernel_size, \n",
    "                                                                        num_channels=filter_size,\n",
    "                                                                        snnl_weight=snnl_weight)\n",
    "\n",
    "            model = tf.estimator.Estimator(model_fn=model_fn, config=config)\n",
    "\n",
    "            train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=num_steps)\n",
    "            eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, throttle_secs=15)\n",
    "\n",
    "            tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:14:18.599148Z",
     "start_time": "2019-07-26T06:14:13.712045Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/data/jma/model/resnet10_test/kernel7_filter8_snnl0.0/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb8495d7898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "in gpu part\n",
      "<tf.Variable 'Resnet-10/conv_0/conv2d/kernel:0' shape=(7, 7, 1, 8) dtype=float32_ref>\n",
      "Tensor(\"plot_conv_weights:0\", shape=(?, ?, 4), dtype=uint8)\n",
      "INFO:tensorflow:Summary name weight plots is illegal; using weight_plots instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-26-06:14:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/jma/model/resnet10_test/kernel7_filter8_snnl0.0/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "4\n",
      "2\n",
      "[[-0.02845679 -0.0220855   0.17962348 -0.02360439  0.11460532  0.2690393\n",
      "   0.07046776]\n",
      " [ 0.00935157 -0.03362369 -0.09703745  0.07564807 -0.40758255  0.05503199\n",
      "  -0.18357578]\n",
      " [-0.35843065 -0.04271042 -0.15174353 -0.19077934  0.05864139 -0.36187923\n",
      "   0.03196693]\n",
      " [-0.03626585 -0.39463624 -0.03681598  0.2111641   0.20942253  0.35966218\n",
      "   0.0874482 ]\n",
      " [ 0.12608945  0.07860761 -0.03803685  0.3893226  -0.09648777 -0.16775636\n",
      "   0.06245267]\n",
      " [ 0.07804557  0.02844388 -0.0927057   0.23109645 -0.27693412 -0.06892431\n",
      "  -0.12014515]\n",
      " [-0.02119025  0.04404238 -0.05966965  0.09388018 -0.09574017  0.1196809\n",
      "   0.268691  ]]\n",
      "[[-1.5368150e-01 -1.7373255e-02  1.4777499e-01 -2.2495134e-01\n",
      "  -3.0675805e-01 -1.1421456e-02 -3.6024541e-01]\n",
      " [-4.2190889e-01  5.4107692e-02  4.5511372e-02  2.9470436e-02\n",
      "  -1.4170438e-01 -3.6201486e-01  2.3649158e-01]\n",
      " [ 3.6773056e-01 -2.4673128e-01 -3.0463606e-01 -1.8315867e-01\n",
      "   7.9335913e-02  5.5566002e-02 -2.5984848e-01]\n",
      " [-1.9112100e-01  2.5559646e-01 -1.9990873e-02 -1.3998052e-02\n",
      "  -1.5465710e-01  2.8288722e-01 -7.0787333e-02]\n",
      " [ 2.0347510e-01 -3.9633355e-01  1.4041543e-01  1.1090395e-02\n",
      "   4.1591573e-01 -2.7527163e-02 -1.3656659e-01]\n",
      " [-1.7285484e-01  5.4798160e-02 -6.2807791e-02  6.6257715e-02\n",
      "   9.8742254e-02 -9.6817121e-02  2.9445266e-02]\n",
      " [ 2.9744615e-04 -9.7842962e-02 -2.6530054e-01 -2.7386227e-01\n",
      "   2.2607046e-01 -1.8562627e-01  1.1078292e-02]]\n",
      "[[-0.04270786  0.16209434 -0.4441318   0.04852578 -0.31149366  0.26793137\n",
      "  -0.3612967 ]\n",
      " [ 0.2704965  -0.36535624  0.15765356  0.01953715  0.28816533 -0.2923741\n",
      "  -0.26532185]\n",
      " [ 0.14689346  0.33163843  0.45278555  0.32427722  0.24213578 -0.180979\n",
      "  -0.31874797]\n",
      " [ 0.09938823 -0.02923644 -0.1618669   0.00892445 -0.07648443  0.17689334\n",
      "   0.28006685]\n",
      " [ 0.02887878 -0.3906602   0.19260848  0.14506617  0.12469862 -0.32043865\n",
      "   0.3260122 ]\n",
      " [ 0.18243495  0.12026965 -0.11040335  0.03795639 -0.14514486 -0.08841004\n",
      "   0.15810506]\n",
      " [-0.19247285 -0.12836295  0.20819497 -0.05984747 -0.43264583 -0.15590908\n",
      "   0.28524047]]\n",
      "[[-0.30187926 -0.19144711  0.09119713  0.08046532  0.16493985  0.13491827\n",
      "  -0.08281673]\n",
      " [ 0.04196882  0.09813663 -0.02896524  0.11723854 -0.03707764 -0.10633323\n",
      "  -0.15525763]\n",
      " [ 0.05221496  0.29943225 -0.23572032 -0.10409057 -0.12855248  0.298367\n",
      "  -0.00263914]\n",
      " [-0.20445794 -0.21457697  0.21908821  0.08366222  0.28223965  0.27008933\n",
      "  -0.19556035]\n",
      " [ 0.12421388 -0.08171744  0.00951014 -0.32953188 -0.22297333  0.12866624\n",
      "   0.32763973]\n",
      " [-0.17427012 -0.17283766  0.03971485 -0.09292379  0.4539594   0.1748376\n",
      "  -0.02069675]\n",
      " [ 0.30130994  0.06003349  0.24852583  0.3163005  -0.36168674  0.03354186\n",
      "  -0.00133022]]\n",
      "[[ 0.06555673 -0.37141874  0.2699209   0.14113401  0.270034    0.3835821\n",
      "   0.20711711]\n",
      " [-0.03206541 -0.17635277  0.22405407  0.12351512  0.08635292 -0.39199185\n",
      "   0.28019047]\n",
      " [-0.07547119  0.31196946  0.03628258 -0.14039704 -0.12753017 -0.19615157\n",
      "   0.11040226]\n",
      " [ 0.11828197  0.08066361  0.3349224  -0.04738507  0.3390781   0.0616983\n",
      "  -0.3418528 ]\n",
      " [ 0.23967434  0.0141956   0.24656898  0.09563182 -0.17960694 -0.00783693\n",
      "   0.16754282]\n",
      " [ 0.11180368 -0.32155493 -0.20284335 -0.458669   -0.16391711  0.09889106\n",
      "  -0.22044466]\n",
      " [ 0.34124497  0.08777816 -0.03996015  0.0837624  -0.00822677  0.05635924\n",
      "  -0.4491678 ]]\n",
      "[[-0.0060112   0.2840179   0.322616    0.34168342  0.06692014 -0.21742426\n",
      "  -0.07365414]\n",
      " [-0.04013987  0.10456266  0.03788685  0.3058537  -0.1711054   0.13962881\n",
      "  -0.3402224 ]\n",
      " [-0.10954838 -0.08822053 -0.20868455  0.04933631 -0.06754658 -0.10689227\n",
      "   0.21048887]\n",
      " [ 0.2526651   0.11246992  0.1805378  -0.14438084 -0.4178523  -0.17309144\n",
      "   0.05917284]\n",
      " [-0.01228519 -0.32061458  0.21281226  0.21232998 -0.15416354 -0.22338744\n",
      "  -0.3889783 ]\n",
      " [-0.2965853  -0.02332459 -0.29452324 -0.28018892 -0.11409844  0.02185939\n",
      "  -0.11218598]\n",
      " [ 0.32765713  0.22919616  0.0112025   0.20264031 -0.3283429   0.21514009\n",
      "  -0.16005078]]\n",
      "[[ 0.45905775 -0.00580839  0.08918231  0.2298696  -0.41472325  0.10322598\n",
      "   0.02562945]\n",
      " [-0.37952295  0.204006    0.19572686 -0.0961772   0.15238011  0.06558795\n",
      "   0.26359284]\n",
      " [ 0.13611455 -0.09942714 -0.12131166  0.43325248  0.14407012  0.02325489\n",
      "   0.2468676 ]\n",
      " [ 0.00939225  0.319177    0.19897053 -0.03578622 -0.17276488  0.04230691\n",
      "  -0.32068273]\n",
      " [-0.34707484  0.08416484 -0.33221018  0.31374195  0.02274315 -0.18072103\n",
      "   0.08780468]\n",
      " [ 0.24443938  0.31852344  0.34604788  0.2862569   0.00506243  0.21145146\n",
      "  -0.11064327]\n",
      " [ 0.11976691 -0.25597233  0.13605207  0.16721985 -0.26065087  0.1676928\n",
      "   0.13206895]]\n",
      "[[-0.36362368  0.15102127 -0.04299828  0.06158469  0.1732734   0.18122345\n",
      "   0.282733  ]\n",
      " [ 0.02157697  0.18681033 -0.13752203  0.09763196 -0.0373747   0.22816083\n",
      "  -0.03812483]\n",
      " [-0.15017894 -0.230693    0.21764591 -0.2583231   0.1696976   0.33920053\n",
      "  -0.13324544]\n",
      " [ 0.07848728  0.0670853   0.0342455   0.00459436 -0.03928013 -0.22700447\n",
      "   0.3229068 ]\n",
      " [ 0.14063871 -0.01856855  0.24867219 -0.24048917 -0.00632039  0.10469659\n",
      "   0.08119974]\n",
      " [-0.10668643  0.06518688 -0.09035753 -0.0999581   0.32728446 -0.04721868\n",
      "  -0.02429677]\n",
      " [-0.10966265  0.2955642   0.31286725 -0.00528507  0.1610457  -0.16118112\n",
      "   0.34318697]]\n",
      "4\n",
      "2\n",
      "[[-0.02845679 -0.0220855   0.17962348 -0.02360439  0.11460532  0.2690393\n",
      "   0.07046776]\n",
      " [ 0.00935157 -0.03362369 -0.09703745  0.07564807 -0.40758255  0.05503199\n",
      "  -0.18357578]\n",
      " [-0.35843065 -0.04271042 -0.15174353 -0.19077934  0.05864139 -0.36187923\n",
      "   0.03196693]\n",
      " [-0.03626585 -0.39463624 -0.03681598  0.2111641   0.20942253  0.35966218\n",
      "   0.0874482 ]\n",
      " [ 0.12608945  0.07860761 -0.03803685  0.3893226  -0.09648777 -0.16775636\n",
      "   0.06245267]\n",
      " [ 0.07804557  0.02844388 -0.0927057   0.23109645 -0.27693412 -0.06892431\n",
      "  -0.12014515]\n",
      " [-0.02119025  0.04404238 -0.05966965  0.09388018 -0.09574017  0.1196809\n",
      "   0.268691  ]]\n",
      "[[-1.5368150e-01 -1.7373255e-02  1.4777499e-01 -2.2495134e-01\n",
      "  -3.0675805e-01 -1.1421456e-02 -3.6024541e-01]\n",
      " [-4.2190889e-01  5.4107692e-02  4.5511372e-02  2.9470436e-02\n",
      "  -1.4170438e-01 -3.6201486e-01  2.3649158e-01]\n",
      " [ 3.6773056e-01 -2.4673128e-01 -3.0463606e-01 -1.8315867e-01\n",
      "   7.9335913e-02  5.5566002e-02 -2.5984848e-01]\n",
      " [-1.9112100e-01  2.5559646e-01 -1.9990873e-02 -1.3998052e-02\n",
      "  -1.5465710e-01  2.8288722e-01 -7.0787333e-02]\n",
      " [ 2.0347510e-01 -3.9633355e-01  1.4041543e-01  1.1090395e-02\n",
      "   4.1591573e-01 -2.7527163e-02 -1.3656659e-01]\n",
      " [-1.7285484e-01  5.4798160e-02 -6.2807791e-02  6.6257715e-02\n",
      "   9.8742254e-02 -9.6817121e-02  2.9445266e-02]\n",
      " [ 2.9744615e-04 -9.7842962e-02 -2.6530054e-01 -2.7386227e-01\n",
      "   2.2607046e-01 -1.8562627e-01  1.1078292e-02]]\n",
      "[[-0.04270786  0.16209434 -0.4441318   0.04852578 -0.31149366  0.26793137\n",
      "  -0.3612967 ]\n",
      " [ 0.2704965  -0.36535624  0.15765356  0.01953715  0.28816533 -0.2923741\n",
      "  -0.26532185]\n",
      " [ 0.14689346  0.33163843  0.45278555  0.32427722  0.24213578 -0.180979\n",
      "  -0.31874797]\n",
      " [ 0.09938823 -0.02923644 -0.1618669   0.00892445 -0.07648443  0.17689334\n",
      "   0.28006685]\n",
      " [ 0.02887878 -0.3906602   0.19260848  0.14506617  0.12469862 -0.32043865\n",
      "   0.3260122 ]\n",
      " [ 0.18243495  0.12026965 -0.11040335  0.03795639 -0.14514486 -0.08841004\n",
      "   0.15810506]\n",
      " [-0.19247285 -0.12836295  0.20819497 -0.05984747 -0.43264583 -0.15590908\n",
      "   0.28524047]]\n",
      "[[-0.30187926 -0.19144711  0.09119713  0.08046532  0.16493985  0.13491827\n",
      "  -0.08281673]\n",
      " [ 0.04196882  0.09813663 -0.02896524  0.11723854 -0.03707764 -0.10633323\n",
      "  -0.15525763]\n",
      " [ 0.05221496  0.29943225 -0.23572032 -0.10409057 -0.12855248  0.298367\n",
      "  -0.00263914]\n",
      " [-0.20445794 -0.21457697  0.21908821  0.08366222  0.28223965  0.27008933\n",
      "  -0.19556035]\n",
      " [ 0.12421388 -0.08171744  0.00951014 -0.32953188 -0.22297333  0.12866624\n",
      "   0.32763973]\n",
      " [-0.17427012 -0.17283766  0.03971485 -0.09292379  0.4539594   0.1748376\n",
      "  -0.02069675]\n",
      " [ 0.30130994  0.06003349  0.24852583  0.3163005  -0.36168674  0.03354186\n",
      "  -0.00133022]]\n",
      "[[ 0.06555673 -0.37141874  0.2699209   0.14113401  0.270034    0.3835821\n",
      "   0.20711711]\n",
      " [-0.03206541 -0.17635277  0.22405407  0.12351512  0.08635292 -0.39199185\n",
      "   0.28019047]\n",
      " [-0.07547119  0.31196946  0.03628258 -0.14039704 -0.12753017 -0.19615157\n",
      "   0.11040226]\n",
      " [ 0.11828197  0.08066361  0.3349224  -0.04738507  0.3390781   0.0616983\n",
      "  -0.3418528 ]\n",
      " [ 0.23967434  0.0141956   0.24656898  0.09563182 -0.17960694 -0.00783693\n",
      "   0.16754282]\n",
      " [ 0.11180368 -0.32155493 -0.20284335 -0.458669   -0.16391711  0.09889106\n",
      "  -0.22044466]\n",
      " [ 0.34124497  0.08777816 -0.03996015  0.0837624  -0.00822677  0.05635924\n",
      "  -0.4491678 ]]\n",
      "[[-0.0060112   0.2840179   0.322616    0.34168342  0.06692014 -0.21742426\n",
      "  -0.07365414]\n",
      " [-0.04013987  0.10456266  0.03788685  0.3058537  -0.1711054   0.13962881\n",
      "  -0.3402224 ]\n",
      " [-0.10954838 -0.08822053 -0.20868455  0.04933631 -0.06754658 -0.10689227\n",
      "   0.21048887]\n",
      " [ 0.2526651   0.11246992  0.1805378  -0.14438084 -0.4178523  -0.17309144\n",
      "   0.05917284]\n",
      " [-0.01228519 -0.32061458  0.21281226  0.21232998 -0.15416354 -0.22338744\n",
      "  -0.3889783 ]\n",
      " [-0.2965853  -0.02332459 -0.29452324 -0.28018892 -0.11409844  0.02185939\n",
      "  -0.11218598]\n",
      " [ 0.32765713  0.22919616  0.0112025   0.20264031 -0.3283429   0.21514009\n",
      "  -0.16005078]]\n",
      "[[ 0.45905775 -0.00580839  0.08918231  0.2298696  -0.41472325  0.10322598\n",
      "   0.02562945]\n",
      " [-0.37952295  0.204006    0.19572686 -0.0961772   0.15238011  0.06558795\n",
      "   0.26359284]\n",
      " [ 0.13611455 -0.09942714 -0.12131166  0.43325248  0.14407012  0.02325489\n",
      "   0.2468676 ]\n",
      " [ 0.00939225  0.319177    0.19897053 -0.03578622 -0.17276488  0.04230691\n",
      "  -0.32068273]\n",
      " [-0.34707484  0.08416484 -0.33221018  0.31374195  0.02274315 -0.18072103\n",
      "   0.08780468]\n",
      " [ 0.24443938  0.31852344  0.34604788  0.2862569   0.00506243  0.21145146\n",
      "  -0.11064327]\n",
      " [ 0.11976691 -0.25597233  0.13605207  0.16721985 -0.26065087  0.1676928\n",
      "   0.13206895]]\n",
      "[[-0.36362368  0.15102127 -0.04299828  0.06158469  0.1732734   0.18122345\n",
      "   0.282733  ]\n",
      " [ 0.02157697  0.18681033 -0.13752203  0.09763196 -0.0373747   0.22816083\n",
      "  -0.03812483]\n",
      " [-0.15017894 -0.230693    0.21764591 -0.2583231   0.1696976   0.33920053\n",
      "  -0.13324544]\n",
      " [ 0.07848728  0.0670853   0.0342455   0.00459436 -0.03928013 -0.22700447\n",
      "   0.3229068 ]\n",
      " [ 0.14063871 -0.01856855  0.24867219 -0.24048917 -0.00632039  0.10469659\n",
      "   0.08119974]\n",
      " [-0.10668643  0.06518688 -0.09035753 -0.0999581   0.32728446 -0.04721868\n",
      "  -0.02429677]\n",
      " [-0.10966265  0.2955642   0.31286725 -0.00528507  0.1610457  -0.16118112\n",
      "   0.34318697]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-07-26-06:14:17\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.546875, global_step = 100, loss = 2.7068906\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /data/jma/model/resnet10_test/kernel7_filter8_snnl0.0/model.ckpt-100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.546875, 'global_step': 100, 'loss': 2.7068906}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# blue is negative, red is positive\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "kernel_size = 7\n",
    "filter_size = 8\n",
    "snnl_weight = 0.0\n",
    "\n",
    "resnet10_checkpoint_path_base = \"/data/jma/model/resnet10_test/\"\n",
    "\n",
    "model_path = resnet10_checkpoint_path_base + \"kernel\" + str(kernel_size) + \"_filter\" + str(filter_size) + \"_snnl\" + str(snnl_weight)+\"/\"\n",
    "\n",
    "model_fn = lambda features, labels, mode: resnet10_model_fn(features, labels, mode, \n",
    "                                                            conv_kernel=kernel_size, \n",
    "                                                            num_channels=filter_size,\n",
    "                                                            snnl_weight=snnl_weight)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_path)\n",
    "\n",
    "\n",
    "    \n",
    "model.evaluate(eval_input_fn)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T05:05:15.558085Z",
     "start_time": "2019-07-26T05:05:13.498Z"
    }
   },
   "outputs": [],
   "source": [
    "        # had to hard code this\n",
    "#         pca_plt = pca(pre_logits_train, num_observations=64, n_dimensions=2)\n",
    "        \n",
    "     \n",
    "#         print(labels)\n",
    "    \n",
    "\n",
    "#     with tf.device(\"/CPU:0\"):\n",
    "#         color_mapping = {0: sns.xkcd_rgb['bright purple'], 1: sns.xkcd_rgb['lime'], 2: sns.xkcd_rgb['ochre']}\n",
    "#         keys = list(color_mapping.keys())\n",
    "#         values = [color_mapping[k] for k in keys]\n",
    "#         table = tf.contrib.lookup.HashTable(\n",
    "#             tf.contrib.lookup.KeyValueTensorInitializer(keys, values, key_dtype=tf.int64, value_dtype=tf.string), sns.xkcd_rgb['black']\n",
    "#         )\n",
    "\n",
    "#         label_colors = tf.map_fn(lambda x: table.lookup(x), labels, dtype=tf.string)\n",
    "\n",
    "#         @tfplot.autowrap(figsize=(12, 12))\n",
    "#         def plot_scatter(x: np.ndarray, y: np.ndarray, colors:np.ndarray, *, ax):\n",
    "#             ax.scatter(x, y, c=colors)\n",
    "#             ax.legend()\n",
    "\n",
    "#         plot_op = plot_scatter(tf.gather_nd(pca_plt, [[0]]), tf.gather_nd(pca_plt, [[1]]), label_colors) \n",
    "\n",
    "#         plot_op_expanded = tf.expand_dims(plot_op, 0)\n",
    "\n",
    "#         tf.summary.image(\"pca\", plot_op_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T06:18:51.493220Z",
     "start_time": "2019-07-26T06:18:51.486192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_3classes/0/c87f27a1-0a60-4208-b0e0-dd5b36b46754.png', 'data_3classes/1/1ee92fad-dab7-4ea2-a970-c5b10dbb2278.png', 'data_3classes/2/2633fb78-cfef-4d57-853a-6010a5484bf1.png', 'data_3classes/0/ef3db06b-3150-41d9-a0a0-8743c613702a.png', 'data_3classes/0/3eddc491-c7f6-4736-b69f-0582b3f42e2c.png', 'data_3classes/2/c5b8f0bb-1a2e-4134-a7ec-5515b401337c.png', 'data_3classes/0/129d0d39-67cf-4acf-9581-f98b273d5288.png', 'data_3classes/1/39caa510-25c6-43ab-96e7-36ba3bca62ce.png', 'data_3classes/1/723e0ee6-194a-40c7-8def-494a84825ec6.png', 'data_3classes/1/c5c3a3ae-8725-4b90-9d8d-044edd5cd692.png', 'data_3classes/1/50b2f70c-b140-49ad-b0b0-5344b91d2af9.png', 'data_3classes/1/dc3becc6-86ee-40a8-a681-1e874e963ec1.png', 'data_3classes/1/3c458adb-39a7-497a-a770-8a8f46d04321.png', 'data_3classes/1/ccf4871d-a6ca-4ea9-a213-e4036ed2a2dc.png', 'data_3classes/0/fb783f95-c2a8-49cb-9b7d-df6503a5472d.png', 'data_3classes/1/5f6b531b-9163-415d-99fb-c9b96dd2b36a.png', 'data_3classes/2/071be6a8-a8f1-4da1-b616-8c97936d51a0.png', 'data_3classes/1/1d9828a4-32f7-4278-b834-e2a8403d106c.png', 'data_3classes/2/fee94986-7ac4-4a51-ade6-c506973d4220.png', 'data_3classes/0/62378caf-ad3b-4777-b676-a5ecd473a4ca.png', 'data_3classes/1/0b503a75-8678-4f6b-91ed-19e3aa4e3900.png', 'data_3classes/2/5cd8dd37-0a0f-43aa-aa2c-12549518bba1.png', 'data_3classes/1/9d485dd9-8189-4b05-a3c7-5216a2f1030f.png', 'data_3classes/0/18ee8bb4-03a7-4677-8558-935f2d822482.png', 'data_3classes/1/8d09600a-5717-4cd7-9f99-36462960dbde.png', 'data_3classes/0/ccae49e7-1772-45c3-8b4a-9f90ace6ca83.png', 'data_3classes/1/34f397a0-ef12-49dc-b2e9-cde9c5d3e92e.png', 'data_3classes/0/33656def-8461-4c31-aa28-e04f5e189a2c.png', 'data_3classes/1/5a8ddffc-3245-4df7-8f20-b97de441503d.png', 'data_3classes/1/359b3ae6-ded7-47be-a612-c5e8b5136bb8.png', 'data_3classes/2/ae3a0bf3-9aba-420e-8d37-c9794740cd62.png', 'data_3classes/1/34524a28-c2c7-4676-a08a-6088180d0ef1.png', 'data_3classes/1/29a622e7-4aee-4c4d-8f88-7b3b7d7ddf5c.png', 'data_3classes/2/db1b6917-65f0-4aa7-9058-4d740a156755.png', 'data_3classes/1/792e4953-bd15-4990-8676-63c5aca59d81.png', 'data_3classes/1/df5f4103-b5c2-4594-9387-5eac65ab004e.png', 'data_3classes/2/2983c862-edc8-4253-9a6c-70ad990051be.png', 'data_3classes/0/3ddd76ab-e92f-4f6e-a4ce-1a57f2fe709a.png', 'data_3classes/1/934ded87-dee4-4682-9035-fe67aaadcf4a.png', 'data_3classes/1/98f72090-7383-4728-8798-64b8a86e7165.png', 'data_3classes/2/aff434f0-f108-4f2f-bb76-dd605b9c3b57.png', 'data_3classes/1/74307d9d-b0c7-449a-b624-00948efa2198.png', 'data_3classes/0/8563dee9-fa3b-4a99-adc3-e764de0406bc.png', 'data_3classes/1/53873b08-6dc0-4b38-9925-87f252b0fac5.png', 'data_3classes/1/d2d7c79c-256d-4ccc-a2d4-b15122118cd0.png', 'data_3classes/1/819be44b-5472-47e7-9fc8-80489088bca2.png', 'data_3classes/1/67a818e1-915f-4110-9c49-fbeba937367a.png', 'data_3classes/0/8845a7ff-e30e-422d-99d1-d7c668a45743.png', 'data_3classes/0/96ea80e6-e637-4bf5-8d39-18e233945f93.png', 'data_3classes/1/858ce726-efa5-4ecd-b322-2299fb089660.png', 'data_3classes/0/fc86e7fd-a9a6-47e2-8959-36b1974aa8b1.png', 'data_3classes/1/746f392f-a4f9-494c-b6cd-4a99204177cd.png', 'data_3classes/0/f9a33007-9a90-4a00-9fd4-70b0d2dc9536.png', 'data_3classes/1/75816b94-6c52-4507-9d06-161869445c8b.png', 'data_3classes/1/6a245491-38b4-4299-a557-5d065d820065.png', 'data_3classes/2/2a073ec5-37cb-49bd-b98f-adc537c98107.png', 'data_3classes/1/99de62e2-9454-428d-98e8-b69a099b3de7.png', 'data_3classes/1/497ddb92-b166-4396-a3c7-799d1891d4e7.png', 'data_3classes/1/e6d691c0-9161-4f39-b723-b75ba5ded30d.png', 'data_3classes/1/86ab868f-f27f-4f63-90d9-71e1f8a6c4b6.png', 'data_3classes/2/b7cb548f-c0cd-440d-9637-86566bda71fd.png', 'data_3classes/1/3e21da03-4f4c-46ea-be53-d1d19712d5e6.png', 'data_3classes/1/4ec869d0-8282-4e4d-85bb-aa149eb90d99.png', 'data_3classes/1/0741c71b-2dd7-4c50-89bf-421204a6a268.png', 'data_3classes/0/348a55e6-7a6d-4cc7-80cd-293ceff2fead.png', 'data_3classes/0/a2d1038a-124e-4932-8b4f-2fb3fba0bb20.png', 'data_3classes/1/d92341cb-8af7-411b-be30-ed826683b17a.png', 'data_3classes/1/ef86ac93-81b3-415c-9136-ba369e02e90c.png', 'data_3classes/2/8a307da3-9ac1-4939-ae3f-2616cb4838ce.png', 'data_3classes/1/0a44f7d7-7f76-419b-92cb-381d21aaddbb.png', 'data_3classes/1/474b881a-2aaa-4504-a16d-0089585d97e8.png', 'data_3classes/1/db27498e-c9a8-49b9-8759-9a09c9717029.png', 'data_3classes/0/49ea6b34-cb50-4ff2-8027-300c288c4d13.png', 'data_3classes/1/5f0de084-d263-4494-a4d7-cd5c3e3aa214.png', 'data_3classes/1/b0916b21-0ccf-4824-a817-9c6b52d8c36f.png', 'data_3classes/0/342826e9-330f-4969-a51c-beda0f8dcf2b.png', 'data_3classes/1/b0a719c4-33dd-4269-af8a-ee3ae2b7a760.png', 'data_3classes/1/6bd02337-aca1-49b8-b54a-ca612e980c4f.png', 'data_3classes/2/b8c4fb4a-c4d7-4b61-a8a2-12836e352cd2.png', 'data_3classes/1/5d9deeb5-9257-4896-92bd-129c8fcd79e0.png', 'data_3classes/2/589162f7-f14a-499f-88dc-64db882c618b.png', 'data_3classes/1/fbcef938-a010-4dc6-82bb-65f9094c5202.png', 'data_3classes/1/8b25a2e9-3560-4e55-b9e6-3d4396ae6f06.png', 'data_3classes/1/663ce284-716d-4712-9748-e53ea8b56c3c.png', 'data_3classes/1/f2741797-f821-4e06-976c-8530f00a7327.png', 'data_3classes/0/d776d6fe-40e4-4433-bc2a-4002a0369111.png', 'data_3classes/1/a07c044c-dd11-41fb-b330-8d21310e181d.png', 'data_3classes/0/0e529a41-057a-444b-914f-481ac3d93b30.png', 'data_3classes/2/b90f2f00-575c-48e0-b04b-a3557d50ec17.png', 'data_3classes/1/5f5a7381-15bc-42fb-9bf2-8100301bbc9b.png', 'data_3classes/0/72929645-a59b-42ec-831e-b4b7135d08e4.png', 'data_3classes/1/7be341f2-8121-4785-b87b-2ae546897051.png', 'data_3classes/0/3ca5e25d-5ea8-476e-a660-21d298f95a00.png', 'data_3classes/0/429be7a1-0a48-46bc-a9d0-27446fdd00d7.png', 'data_3classes/0/1cc3078e-d2d1-4f6e-93ee-118b1f382eee.png', 'data_3classes/1/ff267808-f3d0-4dea-b895-ed2b1e357fc9.png', 'data_3classes/1/f005335a-56d4-4b76-820c-d641ef04215d.png', 'data_3classes/1/5dfcbdba-3c78-4178-90aa-56cdda150ab1.png', 'data_3classes/2/848de9a4-826c-471d-a4ef-50f16a312f9e.png', 'data_3classes/1/74b6da21-4e45-4d25-a26e-af0ae226174d.png', 'data_3classes/0/61ea183c-ba1c-430d-9c82-27efed6fedd5.png', 'data_3classes/1/1c8e5ad5-6a81-41f5-aaeb-5b92e14dc223.png', 'data_3classes/2/8fa86ee7-728d-471a-a966-fe01958cd205.png', 'data_3classes/1/78054889-d4ae-4a43-9ea8-ac6c34b368e9.png', 'data_3classes/1/b5db2185-606e-467b-b3f2-9757419c1d48.png', 'data_3classes/1/eb01b781-2608-4470-b8bc-4c1e669083d1.png', 'data_3classes/1/40e3de28-9cdc-46fd-be62-e3cec615a1c3.png', 'data_3classes/0/697a5762-4eef-4df3-b91a-dac8599865fb.png', 'data_3classes/1/f86112b8-afa5-4009-bc68-e78667efe066.png', 'data_3classes/1/b6e3eb39-fcd2-4b5c-bd9b-a2900d4bba02.png', 'data_3classes/1/b299713a-c90d-4459-a01a-7b77f0422413.png', 'data_3classes/1/1e7e4ef9-dd4e-4f03-abc7-ff713d17b15c.png', 'data_3classes/0/7d3859aa-825e-46ce-a7fd-81a65be42ad4.png', 'data_3classes/2/37b337cb-eb55-4b78-96e2-103b3c63fd98.png', 'data_3classes/1/a8ba17d2-8558-41c8-b2d3-6d64ea002874.png', 'data_3classes/1/2f4f0d4c-0575-4f5b-90a4-bc74f76ba5c1.png', 'data_3classes/0/1cc4acad-a6e2-4053-be31-ecca056a5de3.png', 'data_3classes/1/bdf2e964-0281-4cb6-9679-660f73404178.png', 'data_3classes/0/c39b8a8f-f7b6-4639-8a11-3e791b4749a2.png', 'data_3classes/0/227a5175-0089-4337-b71c-19e4687f25d5.png', 'data_3classes/1/a429bc4e-05d0-4476-a60e-7c5085cad80c.png', 'data_3classes/0/97c048f1-4aff-4c6a-b46a-b6f07b3739c1.png', 'data_3classes/0/1d869ad0-4e90-4f5f-b133-87a1679c9fbb.png', 'data_3classes/0/839c27e8-5075-4d3f-9cdd-baa93b099709.png', 'data_3classes/0/f1fc27e5-52a2-4455-b6a3-8ba47e561291.png', 'data_3classes/1/7359971c-f521-42fa-b793-9b24c25e4be2.png', 'data_3classes/0/291c3c51-d7bd-486c-b0f6-28d2818644ee.png', 'data_3classes/2/1c341d48-d599-4664-b7e6-505f02b3d262.png', 'data_3classes/0/b06c04ed-1937-4a96-bb34-9b11613c15ed.png', 'data_3classes/1/0bc1e6e1-fc3d-4569-91fb-86c61050d74d.png', 'data_3classes/1/46b2adca-aaac-4519-bb68-8145c2a90669.png', 'data_3classes/1/299df80d-05f3-4345-b8cf-1323cb105085.png', 'data_3classes/0/297a417a-9f34-4345-9d62-246ef808121f.png', 'data_3classes/1/5c9d873b-6f8b-408c-8aef-d2527c063f52.png', 'data_3classes/2/921325a0-a281-494f-bfad-e237d4734eac.png', 'data_3classes/1/1879d82a-6d11-4f2d-939e-d7dfb92b2892.png', 'data_3classes/1/fad09ab5-01ee-4c21-8d6a-53c17cac97cf.png', 'data_3classes/0/7f6a9982-4c83-47c7-9a32-3dfc854e8e10.png', 'data_3classes/2/d03cea2b-87f2-4d1e-8cf4-2d2698fa4613.png', 'data_3classes/1/eb142ccd-a193-42ab-8693-94e67b279021.png', 'data_3classes/1/e288e562-af48-40a4-9c1b-cd30051147b5.png', 'data_3classes/1/c35ada4f-c0d9-4c1e-9db9-b7766a7d9278.png', 'data_3classes/0/a4d1bda5-5652-4071-a2cf-c61f83e3498f.png', 'data_3classes/1/e0427ce9-22c3-4ecd-af5d-aff7368d060a.png', 'data_3classes/1/f3701d47-e7c2-45fd-8577-f995113089ee.png', 'data_3classes/1/126de72b-2bea-43a1-9cdb-0aa2d6b56407.png', 'data_3classes/0/3ec27aa6-680c-4f96-b85c-4347ddd3ba2f.png', 'data_3classes/0/4202f21c-d52d-4bc1-bc63-d9836205705f.png', 'data_3classes/0/6fcb13da-55dc-4ff9-ad33-bd8cbec74d8f.png', 'data_3classes/1/77a6202d-7e1c-49fb-81d2-87d00fb0e3f0.png', 'data_3classes/0/3efec947-83d8-419c-ac33-dcfcb445dc5c.png', 'data_3classes/1/15437981-59c7-484f-a085-ebf8c9b64244.png', 'data_3classes/0/f5beb5d4-d902-48ea-bd46-b4aef0ffc8d3.png', 'data_3classes/0/943a8ba6-ec66-4442-a28f-5e2be2142a2a.png', 'data_3classes/1/f253c5a9-f261-497a-97f5-aee95d54f28a.png', 'data_3classes/1/c3ce856c-5ff3-430c-aaaa-afd93e09b2b5.png', 'data_3classes/0/655fb47e-f51f-46f3-ac18-e7833bcacc94.png', 'data_3classes/2/3e05242a-932c-4553-a378-aea784f0411d.png', 'data_3classes/1/ce739ca7-2123-4d62-94cf-31e3d44d0f9b.png', 'data_3classes/2/2687c809-a509-4198-9f48-cd03aca29b50.png', 'data_3classes/2/27af9bac-5d2c-4d56-921b-f27c33b8053a.png', 'data_3classes/1/0c356812-c917-4bcc-9d6f-3f3ca2e33852.png', 'data_3classes/2/02d16b9c-40d2-4ebe-9b0e-1e3ca8613bfb.png', 'data_3classes/1/961f6da6-97f5-482b-8f7e-a4d946b95c83.png', 'data_3classes/0/a1751687-a440-4813-9791-69fa85871d68.png', 'data_3classes/1/a9e3283c-4c4a-466e-9d04-f0def98af099.png', 'data_3classes/0/d58d98fd-9ab1-41da-b8f3-e123733eaa99.png', 'data_3classes/1/ae1ccf45-8e24-4f13-be45-5c304a3eb935.png', 'data_3classes/1/b1772a43-a662-4d78-8f78-717c1dd97dd2.png', 'data_3classes/1/e028e193-27a3-43ab-b6ad-bca212a0f212.png', 'data_3classes/1/ba31d454-e7e5-487d-bde5-bf6ff1e7a8dc.png', 'data_3classes/0/7030d7a5-5982-41ef-9c9a-b3e4030ece9c.png', 'data_3classes/2/25e45110-975a-4144-93a4-738dd8b44a41.png', 'data_3classes/0/b9e66e76-958d-4875-8084-38d78bb1e64e.png', 'data_3classes/1/acdeb1a9-3e58-42d3-9155-46d87ab28b2e.png', 'data_3classes/2/bcc65068-44a6-478c-8759-42ba3ec1ca7e.png', 'data_3classes/0/ce693682-c944-4c46-a55b-a0e19b1b51be.png', 'data_3classes/1/5e35b7da-e74d-4195-9c44-e4bf62494908.png', 'data_3classes/1/ad5b4b23-6767-4d0c-b66e-4621bb56ba51.png', 'data_3classes/0/0ed32200-3672-4db3-b98c-81e406f03ad3.png', 'data_3classes/0/fcf976ac-ea21-40e9-8979-5a0343912834.png', 'data_3classes/0/d6edbcaf-94b7-4c7b-aa94-40bcf3b5d6f0.png', 'data_3classes/1/fb27f400-a68b-4da8-b0d1-c66462b585fe.png', 'data_3classes/1/7625387a-ed8e-43c0-ac9b-ed11f84c3f2f.png', 'data_3classes/1/23bb12e6-9bda-4853-b831-b85be54b4d4f.png', 'data_3classes/1/b393260c-3738-42f2-b129-29640d802618.png', 'data_3classes/0/374ea495-6d80-4ae5-af49-f49babc7a388.png', 'data_3classes/2/7d9963ec-b14b-42c4-a539-e5f73a5b8bdc.png', 'data_3classes/1/f9d2c928-6cfe-4081-a597-1ae77f9243d0.png', 'data_3classes/1/8316772a-a5e4-4567-b0be-b9576811139c.png', 'data_3classes/1/dcaaa2ae-3102-45f4-b01b-20a2d2c7537f.png', 'data_3classes/1/7c1e4cdb-fe3c-4acd-af00-eff81c2b46d1.png', 'data_3classes/1/94f112d7-9bf2-4c6d-a430-dfe4b50d8ba1.png', 'data_3classes/1/630a5ef6-56a6-4680-bd92-923176f3a7f1.png', 'data_3classes/0/e747ddaa-0231-4fa3-808d-0cbe1af33f18.png', 'data_3classes/2/2fd3c9ed-49c2-4f05-8a7c-d522394d1a16.png', 'data_3classes/1/231c8610-6a4c-47db-9e84-addcf412433c.png', 'data_3classes/1/dcf028f3-fe6d-47f8-8cca-3384a57e910d.png', 'data_3classes/1/f9c78131-a097-4e5e-a6bc-22781300203b.png', 'data_3classes/1/381b8ec1-f3d9-4d4f-8f7c-fbb4ddeeacea.png', 'data_3classes/2/91d17110-fbc5-4aee-816c-f6312add83fa.png', 'data_3classes/1/23b1d858-6ed2-4491-aba6-00e4585a8441.png', 'data_3classes/1/2b215d63-d3ad-4028-8634-98c4c7258800.png', 'data_3classes/1/cc400d1a-38c9-4d45-95e6-58794a6be477.png', 'data_3classes/0/9f76fc0f-1990-421b-b065-bc9ebbda48d7.png', 'data_3classes/0/e4124f77-63f3-4da3-9094-bd711a0a1dab.png', 'data_3classes/0/685f0bfd-7a12-40ad-827a-6993c73a800c.png', 'data_3classes/1/95a52881-2d77-4c49-912a-5185f079a6b3.png', 'data_3classes/0/5de28412-7202-491c-b437-2be7ae18a10f.png', 'data_3classes/1/38f2063f-f553-43fd-955c-8bdc2e49288f.png', 'data_3classes/1/77323e2e-6c02-4b36-a071-3b78ae618db4.png', 'data_3classes/1/50a8106a-59b3-4e81-a49c-8a671569748b.png', 'data_3classes/1/4a340a69-971c-4598-b380-305e0f5d650f.png', 'data_3classes/0/6c6482f8-d210-489b-8f69-a66c419aa46a.png', 'data_3classes/1/e12a81ff-5a3d-4f6a-8d63-4315cad6fc19.png', 'data_3classes/1/1d87add6-4170-44db-b788-441e63ad7f92.png', 'data_3classes/1/d999276f-452f-44d5-b56c-cd740533f8c1.png', 'data_3classes/1/d5a4e7be-3585-4b51-a2c6-60a70e972d9b.png', 'data_3classes/1/e2f28ee5-ce75-4b86-9d6b-d2843470536e.png', 'data_3classes/2/0ba2199d-1e45-4dfd-9c43-d6f5422efcee.png', 'data_3classes/1/f0976839-6c29-4a57-965f-4811e11048e4.png', 'data_3classes/1/e4189b96-41f1-4942-99e2-62ccda129950.png', 'data_3classes/1/0857dc04-7d98-4b09-a239-17ef47c22d66.png', 'data_3classes/2/cb9d2c16-c6fe-47fe-b539-8c68fa983f49.png', 'data_3classes/1/53bfcfe1-ef1a-4af0-b11a-391981923e9c.png', 'data_3classes/1/dff17a19-9a02-48e4-8f6d-86958088bef7.png', 'data_3classes/0/81ec02ed-3d4c-4eca-bfff-f87a8beee03d.png', 'data_3classes/0/30f4b6c5-f636-49f2-b35c-486ec6d41a1d.png', 'data_3classes/0/57a5e809-d89c-46bd-a43f-7c8d196808c6.png', 'data_3classes/1/b2c8198b-49b2-452c-beae-db926e4c5e41.png', 'data_3classes/0/aec119ea-4715-493e-aa24-e76358cff422.png', 'data_3classes/1/32be498d-05a5-48aa-b143-e8cd2b5c175f.png', 'data_3classes/1/450a116d-8368-4823-a34d-06f47d7837ac.png', 'data_3classes/0/89ea8506-18ed-4ad9-8c89-dd755902db3c.png', 'data_3classes/1/dbf99a0b-eda8-4edd-ab8b-90fce4c8c756.png', 'data_3classes/1/c1ae651a-5e61-4eec-ac11-24406f2dc82d.png', 'data_3classes/1/0f23eede-ae28-4940-b12c-b2c21c645305.png', 'data_3classes/2/2d49c9bc-91ce-48c4-b1df-50fd9aa426e7.png', 'data_3classes/1/ee0087c6-e8a8-4f10-8e2a-40a3ac4f728a.png', 'data_3classes/2/ec4f0da1-b569-4776-8537-f9652b867d70.png', 'data_3classes/0/a6cb0ddb-6323-42db-81fe-d399990b2dcb.png', 'data_3classes/1/a6a97b9f-454e-4a12-ade3-99ad569de76f.png', 'data_3classes/2/8bd16e0b-1578-42c2-bac6-dfb79565f748.png', 'data_3classes/1/5db5d5ae-a8b6-4d11-81e7-ef58521bbb40.png', 'data_3classes/2/a28427a6-8e64-492b-ab8b-84c359c1289a.png', 'data_3classes/1/abe99218-5dae-469b-ad73-c6c83ddc9cd5.png', 'data_3classes/1/6dc23bbd-b507-4ddb-86ec-08d866305bf6.png', 'data_3classes/2/33dfd5b8-9135-48df-98a0-79bbc7c5b032.png', 'data_3classes/1/9957802e-3033-4ce0-8ddc-0f44710978a0.png', 'data_3classes/0/c5a553a0-bac6-4b19-ab5b-cf261a8c1c00.png', 'data_3classes/1/1b4ce750-f706-4176-8b68-7f6080ce4fe9.png', 'data_3classes/0/c4ce8fbe-55b5-46f3-ac88-4c00de40b178.png', 'data_3classes/1/0da98ff2-bdfa-487f-b32a-7685b524fcaf.png', 'data_3classes/1/55ce9596-df98-4361-a7dd-daea02c00255.png', 'data_3classes/1/630fb01e-0de9-4b8b-a6a7-72dcd347cd66.png', 'data_3classes/1/5385ae31-5711-4817-a622-19e1c9b7f2d0.png', 'data_3classes/2/4c0fc570-c65c-4329-a344-41d47632b3f4.png', 'data_3classes/0/81ee1cc1-16fe-4a1a-9033-cbfe57e0918e.png', 'data_3classes/1/7437c1cf-87ba-4fad-bc6b-ea58e2425852.png', 'data_3classes/2/7a1a439b-788e-4907-bf12-8dccff94f0aa.png', 'data_3classes/1/278ba206-baa8-4ff5-8f7d-95bba5f953e2.png', 'data_3classes/1/e0735b6b-8c69-4f41-a299-80df1a99e80c.png', 'data_3classes/0/ad19c033-48f2-4ce2-9322-0cd025d96dbc.png', 'data_3classes/1/552fe6a6-b2a5-4532-bf7c-8a111003d630.png', 'data_3classes/0/09713e35-c316-4c2d-96b0-78a5ab453a52.png', 'data_3classes/1/321c3260-bbab-48f8-b766-c0dafa7feb4c.png', 'data_3classes/1/9fca132d-018b-4192-a7a5-f95d1de338ce.png', 'data_3classes/1/ff956319-8e59-4c34-b301-d1e6cb268a67.png', 'data_3classes/1/7115fbd7-4028-4230-af9b-e89ef991b217.png', 'data_3classes/1/a44f9ca9-2646-4166-9147-17395aa9d98e.png', 'data_3classes/1/1954ac46-1260-4664-9c64-4bea0eb486a2.png', 'data_3classes/1/d6961751-858d-465f-841c-6bc608a45efa.png', 'data_3classes/1/e2dd9fd2-0a3a-44c7-8115-ea05b828e5b1.png', 'data_3classes/1/7827162a-0b45-4cc1-9f7e-bcef160afff4.png', 'data_3classes/1/fb98153e-50e6-4231-bc1c-2fb95f041693.png', 'data_3classes/0/c32386b6-e6b4-4fbf-b930-167907be7269.png', 'data_3classes/2/f9ec7b24-5769-4c8a-a6f2-4289e31c7110.png', 'data_3classes/0/34b92941-9e3f-4d0c-b624-0ffe6228ec0a.png', 'data_3classes/1/47df3153-9485-4e2e-813e-e9ff56ffb2ef.png', 'data_3classes/0/f5861a43-39d9-43d0-aaf5-dfa750ef3bfe.png', 'data_3classes/0/7a49729b-abef-4f07-b314-04344ff8890d.png', 'data_3classes/1/6f7fd251-1a14-4157-9c67-29f9f43b6bd7.png', 'data_3classes/1/bede0aee-8df4-4a4e-9135-59e2875d427b.png', 'data_3classes/0/f56105ab-06aa-44ce-a689-774b32a276a1.png', 'data_3classes/1/c0562eb4-dc2d-4a00-a492-c83ea8a4c2e8.png', 'data_3classes/0/f3bf1797-84fa-462b-8778-592224e8e7f1.png', 'data_3classes/0/2a4b813d-05dc-4367-aaeb-da85dab40115.png', 'data_3classes/1/5991612a-6c2c-450e-804f-ca4fe00b4047.png', 'data_3classes/1/ecf0a67e-d57a-471a-85e5-cba97a16ec61.png', 'data_3classes/0/4272d072-205f-4e7b-9c1c-d06a29c60f47.png', 'data_3classes/0/b56a45e3-12ed-4cfb-b468-1684d1aeef75.png', 'data_3classes/0/285e023f-94a1-4be3-b806-7896ca178744.png', 'data_3classes/1/527f6fe3-a07c-4823-94a6-b9b3348f07c9.png', 'data_3classes/1/adb2b220-25e3-42ba-aca0-f89c617549a7.png', 'data_3classes/0/9445d662-10ea-4add-9f01-5a1a813f64e5.png', 'data_3classes/1/42f88570-b097-4611-bc1c-14143da981fb.png', 'data_3classes/2/0dc64406-a493-44af-9c06-ad97f6467662.png', 'data_3classes/1/10a653c8-e85f-49fb-b8b3-b9f44703ca9a.png', 'data_3classes/1/bc666c83-ae4d-48fa-ab8f-07d784acff2e.png', 'data_3classes/1/35d40ae3-a710-4e6a-8180-1b9f61955442.png', 'data_3classes/1/7fdbb450-a288-4c80-b81f-d9351e2ab211.png', 'data_3classes/2/8a9d593e-54d4-4209-b4c6-f5bda0f609ae.png', 'data_3classes/1/e2f3d6e3-76bf-4849-abe8-06c9b864cde7.png', 'data_3classes/1/a741d9c6-cf75-48b3-a4e7-37e2871d3e92.png', 'data_3classes/2/46d9a262-96ac-4bab-8f71-1fa932f88aaa.png', 'data_3classes/0/40c51017-398d-4913-8b73-cfd700bcc035.png', 'data_3classes/1/586dda34-8599-4472-8d35-ae3b5ce6db3d.png', 'data_3classes/1/437896e2-f9b7-4637-9cb2-dc3dc4a6bba1.png', 'data_3classes/0/5959f2dd-5cbe-43ef-87e5-71ad28c6a210.png', 'data_3classes/1/604f8708-cb70-43ca-bb6f-8d3f7b9c0d2d.png', 'data_3classes/1/a62bc2b6-351c-44a5-bc11-33aa3f2e4f67.png', 'data_3classes/1/d8dd062d-f255-440a-bedb-5b215997ebaa.png', 'data_3classes/0/5ff38c7e-dea2-4985-9d90-8210f4e90ecc.png', 'data_3classes/0/84ac3b77-492e-4f37-af7d-6785d9386598.png', 'data_3classes/0/7ad18b20-2b07-45f0-8c3e-379b1346a3cc.png', 'data_3classes/0/f0059728-b07b-4394-a675-40714f1f1d55.png', 'data_3classes/1/c11bf5b0-8978-4d17-8b4e-78d534620454.png', 'data_3classes/1/f11177a4-6d68-47db-b6d3-efcb82374144.png', 'data_3classes/1/d68389a9-65b3-4cae-bbb9-e7dde905cba0.png', 'data_3classes/1/0ad30ac7-8a9a-4fab-819a-c91a3c147218.png', 'data_3classes/0/5ae034cb-96a7-456c-8eaa-137077eec4a5.png', 'data_3classes/1/44c0ded9-3ac3-4c7e-8365-6ba6bb188751.png', 'data_3classes/1/94f8ec75-e0e6-4a06-9a20-725ab69744b7.png', 'data_3classes/1/14970c9b-cfa1-4879-9441-71ded19a81fb.png', 'data_3classes/0/aa611a5d-633b-40ea-ac9f-a2fd24e69ff5.png', 'data_3classes/2/f0b1600b-cfa5-448d-867e-efbfac2f236f.png', 'data_3classes/1/d2b7de46-2c38-4cc2-9e64-38e5d7bb9ddd.png', 'data_3classes/1/3d269815-b660-4bc1-9a01-2698cd491351.png', 'data_3classes/1/2bf672dc-f63d-48a0-bb7b-41bcbb3e8151.png', 'data_3classes/1/cf4b7d06-874e-4199-9a98-e4735c9bbbcb.png', 'data_3classes/1/86924621-a32a-4c06-88e2-94ff5881c92a.png', 'data_3classes/1/1f2c0253-ddb8-427d-9bcd-7315918fde4b.png', 'data_3classes/1/95691c7d-053f-442a-b58b-2a914a2e9c42.png', 'data_3classes/2/9e8ee439-9d85-4ad7-a5bb-246780cb7a32.png', 'data_3classes/1/670bce02-fa11-4bba-a69c-926817b6d19a.png', 'data_3classes/0/b4c46562-5a7c-4e52-9b86-1545c69a3550.png', 'data_3classes/0/740676ae-273e-49d2-b62a-ef5f123995fc.png', 'data_3classes/1/bd7a3c73-73e4-4c42-ba87-dd2c6468887f.png', 'data_3classes/0/dc8a83cf-d833-4a0f-b026-ef475c00b1fc.png', 'data_3classes/1/2cf629e8-9752-4ebb-b5fe-3433608ae137.png', 'data_3classes/0/49106a52-f70e-4e35-96b0-e2f478a4e1c6.png', 'data_3classes/0/6735e0a8-7744-4724-837a-593f5133e889.png', 'data_3classes/1/46b50333-8233-4857-891e-b9e1c8a8d048.png', 'data_3classes/1/e36ed313-f410-4836-8bae-a43bd83cd421.png', 'data_3classes/1/4f048792-79f9-4ef4-a3bd-0b684c8c2ade.png', 'data_3classes/1/07d934ed-59a1-487b-920d-2fa010b97f9b.png', 'data_3classes/0/7f78ea4a-7f5a-4ead-9d65-2e21049185b7.png', 'data_3classes/0/438906c2-4d4e-4c7f-9c2e-80a4db63f852.png', 'data_3classes/1/7883df94-f577-46b2-9670-42cb1f60139e.png', 'data_3classes/1/66c1f5c8-6bc6-4e56-a7eb-ca13145e9d32.png', 'data_3classes/1/b4c89492-5b60-47ab-a397-c66d0788938a.png', 'data_3classes/1/89ea7435-e038-4cfb-b46c-d01fa09739d8.png', 'data_3classes/2/c98a368c-5493-47dc-8d7e-f3b76a857cc2.png', 'data_3classes/0/4ccc24b4-6dcc-4fc5-8ea7-58823b74ab84.png', 'data_3classes/1/5e19880c-edef-46a4-a933-c9dca97772df.png', 'data_3classes/2/930af6f2-5682-4316-a38d-272c7e52fcb4.png', 'data_3classes/0/f02706ad-3a50-429b-bdff-12f2f069e396.png', 'data_3classes/1/2b00eba3-11d6-4b94-a816-24195a303534.png', 'data_3classes/0/89084419-c83e-422c-be27-04cf86f146ab.png', 'data_3classes/1/b648f57b-0ff0-4fb2-811b-c98ac0b36278.png', 'data_3classes/0/fbbe5548-9288-4fb0-80d9-b2d7b28c8e9e.png', 'data_3classes/1/3ffbd1ed-f979-42cb-9480-95449a3bbf84.png', 'data_3classes/0/52a9785c-2b80-41c0-b68c-188b58a5660b.png', 'data_3classes/1/1e3b46e6-3758-4aa7-a7be-a9a5a3c27e78.png', 'data_3classes/1/cd5b1723-fdaf-4313-9189-38817b7375be.png', 'data_3classes/1/14713b44-d4c9-4d8f-8cb8-bd1319a1747f.png', 'data_3classes/0/3df5ec0a-c945-47a7-98b9-80e097c0dfea.png', 'data_3classes/0/da29501c-d588-428f-89d9-ac8c4c36a0c4.png', 'data_3classes/0/a3d5cde8-313d-4b10-bf30-a5e8516a2d6d.png', 'data_3classes/1/000a837a-271b-4c5a-8235-7b9f4d443fad.png', 'data_3classes/1/e105af8a-d73b-45a8-be29-fc51cb104fef.png', 'data_3classes/1/b9dde05f-86d0-48cf-84c9-fb86a7536b8e.png', 'data_3classes/1/4b95ded8-3f5a-488d-8b0b-35334e3be12e.png', 'data_3classes/1/97589d0c-ae8f-4b2e-a2e9-6e19fe0fa327.png', 'data_3classes/1/f2887327-0bd9-414a-987c-a579b7df3d5c.png', 'data_3classes/1/c6bfa2f3-5f2f-4911-9dc2-a9bbd6305d23.png', 'data_3classes/1/c24ccfdb-47f6-4da6-980f-745285f2f942.png', 'data_3classes/1/b470f9a6-db51-4334-bb86-8a7fe8b8be2c.png', 'data_3classes/2/63dabc33-7fb7-42a2-8f7c-ec49c78288f6.png', 'data_3classes/1/10675ee1-3ccb-4c27-ba5d-2c75460d434f.png', 'data_3classes/2/ff1ecc65-7b57-4b6f-ad5b-9f0f57f09651.png', 'data_3classes/1/feec6796-5f70-40e3-8c9a-e95bfbb4f39b.png', 'data_3classes/1/c5818be9-b813-4616-8159-5521d2e695b8.png', 'data_3classes/1/34cbad15-57aa-49ca-b58c-6e7fda12b0be.png', 'data_3classes/0/9fc0b1a9-ea89-4d30-b040-5c0e5591901d.png', 'data_3classes/2/4bf22dba-f3a0-4de2-9f06-6a48155ea6d0.png', 'data_3classes/1/eb143c68-0b69-4523-b33b-77aa7d4ed743.png', 'data_3classes/1/d74d9c71-e690-4f5d-9de8-a743e7ec1f55.png', 'data_3classes/1/95ed14c4-41f5-41a7-8cfc-53c70209db47.png', 'data_3classes/1/1d80cb16-8d65-4666-ab6c-58f8c4ab0571.png', 'data_3classes/0/a424bc34-75f4-4f02-be8b-44446d418332.png', 'data_3classes/1/53b8ceb1-c3b9-4788-af44-7c67878e3fed.png', 'data_3classes/1/b6751dc7-3935-4830-8b74-054a7a897ca2.png', 'data_3classes/1/a1779958-8521-4021-9f0d-40479f2edcf5.png', 'data_3classes/1/c2819f40-060e-4329-a3f4-b131a7e4c564.png', 'data_3classes/1/c52af94b-f258-4b6d-adaa-9b5d3a98c36f.png', 'data_3classes/1/614debb5-8f1c-4409-bc79-674d6300e6bb.png', 'data_3classes/2/eb3a08f5-ea45-4eb4-a55e-8b504d0c89c9.png', 'data_3classes/1/39af5783-fab1-4b0b-903c-37b4ad930f92.png', 'data_3classes/1/0f2c8e7b-9a4b-42e8-9cfd-3d5d894e1afa.png', 'data_3classes/1/77d63e58-14ca-4e69-878b-cfa969566985.png', 'data_3classes/0/d10c7fa7-66c3-412e-9f51-ae8fe365d368.png', 'data_3classes/0/5c5411e8-1a42-4766-bc15-6f1ebe085a75.png', 'data_3classes/0/0288809c-67d5-4472-b82c-03e37f9582f3.png', 'data_3classes/1/63c84133-2540-4d3e-8172-410da740c4ce.png', 'data_3classes/1/a1b11952-3e50-4003-a239-9a33cfe2e5ad.png', 'data_3classes/2/58520d82-ea15-48bd-9fab-f7f6760f2853.png', 'data_3classes/0/7f433e1c-5948-458a-8285-aafb7e63709f.png', 'data_3classes/1/dfbb9c8e-6f96-48aa-a74a-51f93ffdfed1.png', 'data_3classes/0/dd794356-6013-4372-a61f-5664f003f087.png', 'data_3classes/1/e94f4625-1db4-4bca-9114-5b4e6a336396.png', 'data_3classes/2/244519cb-f04a-4b61-aeda-1d600de690a5.png', 'data_3classes/1/084ba878-7004-4a7e-870e-ca0111ee05f0.png', 'data_3classes/1/f7e71a41-fb64-44e8-9c93-b50876070f8d.png', 'data_3classes/0/35d66ad8-d389-4be1-8f3a-c9e9b9aedc29.png', 'data_3classes/0/fb7ea0cd-b0f9-45e1-86f7-268317bd3cb3.png', 'data_3classes/0/e9cc9d08-10bc-4ba4-a458-06123d09ec27.png', 'data_3classes/0/94a7174d-393e-4948-80bd-34423860baf6.png', 'data_3classes/1/28992e54-ea7b-43da-960f-55b210cbdd26.png', 'data_3classes/0/469246b9-2b63-44da-ac45-8ec4e5deffc2.png', 'data_3classes/2/f90bb192-985b-44fd-9710-68cd4b280057.png', 'data_3classes/2/01811c90-b4db-4e9f-99fc-634aa8b8611c.png', 'data_3classes/0/fe1e2b18-eb20-4271-af14-73c197615050.png', 'data_3classes/0/6dc14913-9458-4102-b261-9b14b63c450c.png', 'data_3classes/1/ca4160de-f488-4fd9-81a3-768140bf2b19.png', 'data_3classes/1/451f4cc6-732c-4501-b99d-362993c2a31b.png', 'data_3classes/2/1e7e4ef9-dd4e-4f03-abc7-ff713d17b15c.png', 'data_3classes/0/13a5475b-6729-44d2-ad3b-fdc5ceb58d3e.png', 'data_3classes/2/3974aeea-b729-4aa0-82a0-0eccac23faa4.png', 'data_3classes/1/fdb217ad-5045-478a-bf20-e01291dd1731.png', 'data_3classes/0/c5c21013-6a9f-43df-b323-1f0f364385ef.png', 'data_3classes/2/0a14f618-9b9f-4d03-8277-88f2793ef2d4.png', 'data_3classes/1/bc7b9ff2-3a66-4121-abe6-c9ebdf1beea1.png', 'data_3classes/2/ff488e9b-81a8-45a1-b4b7-c3528b2fe1b9.png', 'data_3classes/1/29105bf4-25b0-4eaa-839a-64f30c103edb.png', 'data_3classes/1/c510d5d8-2cf6-4ca4-a5f0-86f26c35d052.png', 'data_3classes/1/9a391ffb-5eb0-45df-9b0a-dd7122f91e59.png', 'data_3classes/1/10c3d0dc-c175-4b86-bc7a-baba4baf5e19.png', 'data_3classes/1/b480e262-beaf-471a-874e-8c50413a9a60.png', 'data_3classes/0/f6e93ca4-2023-4098-a754-06872d6e0614.png', 'data_3classes/1/87f538cd-8c22-4f20-ac2b-c410d04ecb10.png', 'data_3classes/2/202e97fa-259a-403a-8093-edcf592a7f41.png', 'data_3classes/1/97a9675c-6945-4edd-9175-5b7d2b9e837f.png', 'data_3classes/0/a3809f1f-234e-4c16-9ebe-bfe5eef99ceb.png', 'data_3classes/1/373df149-4c86-4569-b04f-3f197426a83e.png', 'data_3classes/0/01891d30-b723-463f-a91f-024c4cb6e497.png', 'data_3classes/1/6a0fa9af-8e2b-4513-ae6c-4615ea31fa72.png', 'data_3classes/1/2e26dbfe-ed09-4c9b-8b65-0725d0953db9.png', 'data_3classes/1/69f8f65d-8f63-4c5c-83aa-35b81f579604.png', 'data_3classes/1/3b49855b-5b47-4db7-8532-5e307b93322e.png', 'data_3classes/0/4b3d7c8d-b5ca-499e-b9c5-e04e291cb7f7.png', 'data_3classes/2/a0ab2aa8-55b8-41e7-a2ad-428d578d3adf.png', 'data_3classes/0/d1794621-9c03-4227-88f8-a4119efefe9d.png', 'data_3classes/1/137cc91f-1413-4f78-ba2a-168f3bbdf433.png', 'data_3classes/1/52abb356-c74e-462c-9ea6-ee05747ebbed.png', 'data_3classes/2/e040c1c0-3d60-45ee-9d0e-bc4ed2df9c17.png', 'data_3classes/1/15e5e273-2255-4248-b94b-7ac68d90e319.png', 'data_3classes/1/0c8346d2-0990-4eca-924a-e71683de8638.png', 'data_3classes/0/4357e1dd-a8c6-4354-be9d-235f2f47985b.png', 'data_3classes/0/b28e4f09-9529-4a9d-abf2-c81ffabc5e41.png', 'data_3classes/1/d6f175c6-5732-4fd4-85bc-64d436463468.png', 'data_3classes/1/2ffb638b-00fc-4ac7-8ca3-14ca44ea3c55.png', 'data_3classes/0/d12c983e-3fc2-4e8a-8357-0a6e10ff7ec5.png', 'data_3classes/1/20dac469-4c40-46a7-880c-83c91a6df6e5.png', 'data_3classes/1/d37ecdd9-cf82-4ef2-a51e-0e4463a2e51b.png', 'data_3classes/1/21140ed9-5954-464f-9bc5-54c5d6099797.png', 'data_3classes/2/475ca176-c4ce-4ec1-bf14-d849e8a36f74.png', 'data_3classes/1/9ab52991-32f3-4e70-8334-27b922e8fafd.png', 'data_3classes/1/f82b1829-dae7-4261-8a43-92171524cb6a.png', 'data_3classes/1/2e59dddc-55cb-412c-8bcc-7878a69005c9.png', 'data_3classes/1/7cb03fab-c59e-48b2-8bf9-d7f2cf45b6c9.png', 'data_3classes/1/78ab687f-8b76-4153-b2b1-56fd9f35c962.png', 'data_3classes/1/400f50e0-ace4-4286-96a1-e8cc13bc2b7f.png', 'data_3classes/2/d0743f7e-098e-4a89-a4ab-50073cff8040.png', 'data_3classes/1/5b65f79d-a5c2-4378-8fc2-b11f7fe43c1f.png', 'data_3classes/1/4df4af23-ce38-44fb-a6a5-750d4247b0d3.png', 'data_3classes/1/51b0757d-f73c-411b-a777-90d8c706c651.png', 'data_3classes/2/cfa1ad7d-a8a3-446a-8874-861fb48052f3.png', 'data_3classes/1/08927b70-c4df-47bf-b036-32e0fd8238bd.png', 'data_3classes/0/66a560a7-5947-4557-95d5-eec51b5f8265.png', 'data_3classes/1/5fb3d458-e749-4f6f-a96e-5b25b5817ead.png', 'data_3classes/1/c7fd200c-ccce-4eb9-a4f8-d12378869431.png', 'data_3classes/0/0c6d8cc9-a04b-46dd-b397-ea1106d1488b.png', 'data_3classes/1/1a9bba5f-d857-4457-9033-3a7a9167f395.png']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
